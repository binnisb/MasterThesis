Automatically generated by Mendeley 1.8
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Boisvert2012,
abstract = {ABSTRACT: Voluminous parallel sequencing datasets, especially metagenomic experiments, require distributed computing for de novo assembly and taxonomic profiling. Ray Meta is a massively distributed metagenome assembler that is coupled with Ray Communities, which profiles microbiomes based on uniquely-colored k-mers. It can accurately assemble and profile a three billion read metagenomic experiment representing 1,000 bacterial genomes of uneven proportions in 15 hours with 1,024 processor cores, using only 1.5 GB per core. The software will facilitate the processing of large and complex datasets, and will help in generating biological insights on specific environments. Ray Meta is open source and available at http://denovoassembler.sf.net.},
author = {Boisvert, Sebastien and Raymond, Frederic and Godzaridis, Elenie and Laviolette, Francois and Corbeil, Jacques},
doi = {10.1186/gb-2012-13-12-r122},
file = {::},
issn = {1465-6914},
journal = {Genome biology},
month = dec,
number = {12},
pages = {R122},
pmid = {23259615},
title = {{Ray Meta: scalable de novo metagenome assembly and profiling.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23259615},
volume = {13},
year = {2012}
}
@article{Dick2009,
abstract = {Analyses of DNA sequences from cultivated microorganisms have revealed genome-wide, taxa-specific nucleotide compositional characteristics, referred to as genome signatures. These signatures have far-reaching implications for understanding genome evolution and potential application in classification of metagenomic sequence fragments. However, little is known regarding the distribution of genome signatures in natural microbial communities or the extent to which environmental factors shape them.},
author = {Dick, Gregory J and Andersson, Anders F and Baker, Brett J and Simmons, Sheri L and Thomas, Brian C and Yelton, A Pepper and Banfield, Jillian F},
doi = {10.1186/gb-2009-10-8-r85},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dick et al. - 2009 - Community-wide analysis of microbial genome sequence signatures(4).pdf:pdf},
issn = {1465-6914},
journal = {Genome biology},
keywords = {Bacteria,Bacteria: genetics,Bacteria: metabolism,Genomics,Iron,Mining,Soil Microbiology},
month = jan,
number = {8},
pages = {R85},
pmid = {19698104},
title = {{Community-wide analysis of microbial genome sequence signatures.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2745766\&tool=pmcentrez\&rendertype=abstract},
volume = {10},
year = {2009}
}
@article{Hardenbol2003,
abstract = {We report on the development of molecular inversion probe (MIP) genotyping, an efficient technology for large-scale single nucleotide polymorphism (SNP) analysis. This technique uses MIPs to produce inverted sequences, which undergo a unimolecular rearrangement and are then amplified by PCR using common primers and analyzed using universal sequence tag DNA microarrays, resulting in highly specific genotyping. With this technology, multiplex analysis of more than 1,000 probes in a single tube can be done using standard laboratory equipment. Genotypes are generated with a high call rate (95\%) and high accuracy (>99\%) as determined by independent sequencing.},
author = {Hardenbol, Paul and Ban\'{e}r, Johan and Jain, Maneesh and Nilsson, Mats and Namsaraev, Eugeni a and Karlin-Neumann, George a and Fakhrai-Rad, Hossein and Ronaghi, Mostafa and Willis, Thomas D and Landegren, Ulf and Davis, Ronald W},
doi = {10.1038/nbt821},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/8\_MIP.pdf:pdf},
issn = {1087-0156},
journal = {Nature biotechnology},
keywords = {Cells, Cultured,Chromosomes, Human, Pair 6,Chromosomes, Human, Pair 6: genetics,DNA Mutational Analysis,DNA Mutational Analysis: methods,Expressed Sequence Tags,Gene Expression Profiling,Gene Expression Profiling: methods,Genotype,Humans,Molecular Probe Techniques,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Polymerase Chain Reaction,Polymerase Chain Reaction: methods,Polymorphism, Single Nucleotide,Quality Control,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = jun,
number = {6},
pages = {673--8},
pmid = {12730666},
title = {{Multiplexed genotyping with sequence-tagged molecular inversion probes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12730666},
volume = {21},
year = {2003}
}
@article{Neiman2011,
abstract = {There has been a dramatic increase of throughput of sequenced bases in the last years but sequencing a multitude of samples in parallel has not yet developed equally. Here we present a novel strategy where the combination of two tags is used to link sequencing reads back to their origins from a pool of samples. By incorporating the tags in two steps sample-handling complexity is lowered by nearly 100 times compared to conventional indexing protocols. In addition, the method described here enables accurate identification and typing of thousands of samples in parallel. In this study the system was designed to test 4992 samples using only 122 tags. To prove the concept of the two-tagging method, the highly polymorphic 2(nd) exon of DLA-DRB1 in dogs and wolves was sequenced using the 454 GS FLX Titanium Chemistry. By requiring a minimum sequence depth of 20 reads per sample, 94\% of the successfully amplified samples were genotyped. In addition, the method allowed digital detection of chimeric fragments. These results demonstrate that it is possible to sequence thousands of samples in parallel without complex pooling patterns or primer combinations. Furthermore, the method is highly scalable as only a limited number of additional tags leads to substantial increase of the sample size.},
author = {Neiman, M\aa rten and Lundin, Sverker and Savolainen, Peter and Ahmadian, Afshin},
doi = {10.1371/journal.pone.0017785},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/28\_DNA\_Tagging.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Animals,Dogs,Dogs: genetics,High-Throughput Nucleotide Sequencing,High-Throughput Nucleotide Sequencing: methods,Polymorphism, Genetic,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Wolves,Wolves: genetics},
month = jan,
number = {3},
pages = {e17785},
pmid = {21408018},
title = {{Decoding a substantial set of samples in parallel by massive sequencing.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3052374\&tool=pmcentrez\&rendertype=abstract},
volume = {6},
year = {2011}
}
@article{Gunderson2005,
abstract = {Oligonucleotide probe arrays have enabled massively parallel analysis of gene expression levels from a single cDNA sample. Application of microarray technology to analyzing genomic DNA has been stymied by the sequence complexity of the entire human genome. A robust, single base-resolution direct genomic assay would extend the reach of microarray technology. We developed an array-based whole-genome genotyping assay that does not require PCR and enables effectively unlimited multiplexing. The assay achieves a high signal-to-noise ratio by combining specific hybridization of picomolar concentrations of whole genome-amplified DNA to arrayed probes with allele-specific primer extension and signal amplification. As proof of principle, we genotyped several hundred previously characterized SNPs. The conversion rate, call rate and accuracy were comparable to those of high-performance PCR-based genotyping assays.},
author = {Gunderson, Kevin L and Steemers, Frank J and Lee, Grace and Mendoza, Leo G and Chee, Mark S},
doi = {10.1038/ng1547},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/13\_Illumina\_Whole.pdf:pdf},
issn = {1061-4036},
journal = {Nature genetics},
keywords = {Computational Biology,Genome, Human,Genotype,Humans,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Polymorphism, Single Nucleotide},
month = may,
number = {5},
pages = {549--54},
pmid = {15838508},
title = {{A genome-wide scalable SNP genotyping assay using microarray technology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15838508},
volume = {37},
year = {2005}
}
@article{Wang2012_5,
abstract = {Metagenomic binning remains an important topic in metagenomic analysis. Existing unsupervised binning methods for next-generation sequencing (NGS) reads do not perform well on (i) samples with low-abundance species or (ii) samples (even with high abundance) when there are many extremely low-abundance species. These two problems are common for real metagenomic datasets. Binning methods that can solve these problems are desirable.},
author = {Wang, Yi and Leung, Henry C M and Yiu, S M and Chin, Francis Y L},
doi = {10.1093/bioinformatics/bts397},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2012 - MetaCluster 5.0 a two-round binning approach for metagenomic data for low-abundance species in a noisy sample.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
month = sep,
number = {18},
pages = {i356--i362},
pmid = {22962452},
title = {{MetaCluster 5.0: a two-round binning approach for metagenomic data for low-abundance species in a noisy sample.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3436824\&tool=pmcentrez\&rendertype=abstract},
volume = {28},
year = {2012}
}
@article{Rothberg2011,
abstract = {The seminal importance of DNA sequencing to the life sciences, biotechnology and medicine has driven the search for more scalable and lower-cost solutions. Here we describe a DNA sequencing technology in which scalable, low-cost semiconductor manufacturing techniques are used to make an integrated circuit able to directly perform non-optical DNA sequencing of genomes. Sequence data are obtained by directly sensing the ions produced by template-directed DNA polymerase synthesis using all-natural nucleotides on this massively parallel semiconductor-sensing device or ion chip. The ion chip contains ion-sensitive, field-effect transistor-based sensors in perfect register with 1.2 million wells, which provide confinement and allow parallel, simultaneous detection of independent sequencing reactions. Use of the most widely used technology for constructing integrated circuits, the complementary metal-oxide semiconductor (CMOS) process, allows for low-cost, large-scale production and scaling of the device to higher densities and larger array sizes. We show the performance of the system by sequencing three bacterial genomes, its robustness and scalability by producing ion chips with up to 10 times as many sensors and sequencing a human genome.},
author = {Rothberg, Jonathan M and Hinz, Wolfgang and Rearick, Todd M and Schultz, Jonathan and Mileski, William and Davey, Mel and Leamon, John H and Johnson, Kim and Milgrew, Mark J and Edwards, Matthew and Hoon, Jeremy and Simons, Jan F and Marran, David and Myers, Jason W and Davidson, John F and Branting, Annika and Nobile, John R and Puc, Bernard P and Light, David and Clark, Travis a and Huber, Martin and Branciforte, Jeffrey T and Stoner, Isaac B and Cawley, Simon E and Lyons, Michael and Fu, Yutao and Homer, Nils and Sedova, Marina and Miao, Xin and Reed, Brian and Sabina, Jeffrey and Feierstein, Erika and Schorn, Michelle and Alanjary, Mohammad and Dimalanta, Eileen and Dressman, Devin and Kasinskas, Rachel and Sokolsky, Tanya and Fidanza, Jacqueline a and Namsaraev, Eugeni and McKernan, Kevin J and Williams, Alan and Roth, G Thomas and Bustillo, James},
doi = {10.1038/nature10242},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/26\_Ion\_Torrent.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Escherichia coli,Escherichia coli: genetics,Genome, Bacterial,Genome, Bacterial: genetics,Genome, Human,Genome, Human: genetics,Genomics,Genomics: instrumentation,Genomics: methods,Humans,Light,Male,Rhodopseudomonas,Rhodopseudomonas: genetics,Semiconductors,Sequence Analysis, DNA,Sequence Analysis, DNA: instrumentation,Sequence Analysis, DNA: methods,Vibrio,Vibrio: genetics},
month = jul,
number = {7356},
pages = {348--52},
pmid = {21776081},
publisher = {Nature Publishing Group},
title = {{An integrated semiconductor device enabling non-optical genome sequencing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21776081},
volume = {475},
year = {2011}
}
@article{Ahmadian2011,
author = {Ahmadian, Afshin and Svahn, Helene Andersson},
doi = {10.1039/c1lc90035h},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/29\_Review\_Ahmadian.pdf:pdf},
issn = {1473-0189},
journal = {Lab on a chip},
keywords = {DNA,DNA: genetics,High-Throughput Nucleotide Sequencing,High-Throughput Nucleotide Sequencing: instrumenta,High-Throughput Nucleotide Sequencing: methods,Humans,Lab-On-A-Chip Devices,Sequence Analysis, DNA,Sequence Analysis, DNA: instrumentation,Sequence Analysis, DNA: methods},
month = aug,
number = {16},
pages = {2653--5},
pmid = {21503304},
title = {{Massively parallel sequencing platforms using lab on a chip technologies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21503304},
volume = {11},
year = {2011}
}
@article{Velculescu1995,
author = {Velculescu, V. E. and Zhang, L. and Vogelstein, B. and Kinzler, K. W.},
doi = {10.1126/science.270.5235.484},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/3\_SAGE.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = oct,
number = {5235},
pages = {484--487},
title = {{Serial Analysis of Gene Expression}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.270.5235.484},
volume = {270},
year = {1995}
}
@article{McHardy2007,
abstract = {Metagenome studies have retrieved vast amounts of sequence data from a variety of environments leading to new discoveries and insights into the uncultured microbial world. Except for very simple communities, the encountered diversity has made fragment assembly and the subsequent analysis a challenging problem. A taxonomic characterization of metagenomic fragments is required for a deeper understanding of shotgun-sequenced microbial communities, but success has mostly been limited to sequences containing phylogenetic marker genes. Here we present PhyloPythia, a composition-based classifier that combines higher-level generic clades from a set of 340 completed genomes with sample-derived population models. Extensive analyses on synthetic and real metagenome data sets showed that PhyloPythia allows the accurate classification of most sequence fragments across all considered taxonomic ranks, even for unknown organisms. The method requires no more than 100 kb of training sequence for the creation of accurate models of sample-specific populations and can assign fragments >or=1 kb with high specificity.},
author = {McHardy, Alice Carolyn and Mart\'{\i}n, H\'{e}ctor Garc\'{\i}a and Tsirigos, Aristotelis and Hugenholtz, Philip and Rigoutsos, Isidore},
doi = {10.1038/nmeth976},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mchardy - 2007 - Accurate phylogenetic classification of variable-length DNA fragments.pdf:pdf},
issn = {1548-7091},
journal = {Nature methods},
keywords = {Animals,Archaea,Archaea: genetics,Arthropods,Arthropods: genetics,Ascomycota,Ascomycota: genetics,Bacteria,Bacteria: genetics,Chordata,Chordata: genetics,DNA,DNA: chemistry,DNA: classification,DNA: genetics,Eukaryotic Cells,Genome,Genomics,Genomics: methods,Industrial Waste,Phylogeny,Sargassum,Sargassum: microbiology,Software Validation},
month = jan,
number = {1},
pages = {63--72},
pmid = {17179938},
publisher = {Nature Publishing Group},
shorttitle = {Nat Meth},
title = {{Accurate phylogenetic classification of variable-length DNA fragments.}},
url = {http://dx.doi.org/10.1038/nmeth976},
volume = {4},
year = {2007}
}
@article{Kelley2010,
abstract = {Sequencing of environmental DNA (often called metagenomics) has shown tremendous potential to uncover the vast number of unknown microbes that cannot be cultured and sequenced by traditional methods. Because the output from metagenomic sequencing is a large set of reads of unknown origin, clustering reads together that were sequenced from the same species is a crucial analysis step. Many effective approaches to this task rely on sequenced genomes in public databases, but these genomes are a highly biased sample that is not necessarily representative of environments interesting to many metagenomics projects.},
author = {Kelley, David R and Salzberg, Steven L},
doi = {10.1186/1471-2105-11-544},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelley, Salzberg - 2010 - Clustering metagenomic sequences with interpolated Markov models(3).pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Automated,Automated: methods,Cluster Analysis,DNA,DNA: methods,Databases,Factual,Markov Chains,Metagenomics,Metagenomics: methods,Pattern Recognition,Sequence Analysis},
month = jan,
pages = {544},
pmid = {21044341},
title = {{Clustering metagenomic sequences with interpolated Markov models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3098094\&tool=pmcentrez\&rendertype=abstract},
volume = {11},
year = {2010}
}
@article{Mengersen2013,
abstract = {Approximate Bayesian computation has become an essential tool for the analysis of complex stochastic models when the likelihood function is numerically unavailable. However, the well-established statistical method of empirical likelihood provides another route to such settings that bypasses simulations from the model and the choices of the approximate Bayesian computation parameters (summary statistics, distance, tolerance), while being convergent in the number of observations. Furthermore, bypassing model simulations may lead to significant time savings in complex models, for instance those found in population genetics. The Bayesian computation with empirical likelihood algorithm we develop in this paper also provides an evaluation of its own performance through an associated effective sample size. The method is illustrated using several examples, including estimation of standard distributions, time series, and population genetics models.},
author = {Mengersen, Kerrie L and Pudlo, Pierre and Robert, Christian P},
doi = {10.1073/pnas.1208827110},
file = {:home/binni/Downloads/PNAS-2013-Mengersen-1321-6.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = jan,
number = {4},
pages = {1321--1326},
pmid = {23297233},
title = {{Bayesian computation via empirical likelihood.}},
url = {http://www.pnas.org/cgi/content/long/110/4/1321},
volume = {110},
year = {2013}
}
@article{Johnson2007,
abstract = {In vivo protein-DNA interactions connect each transcription factor with its direct targets to form a gene network scaffold. To map these protein-DNA interactions comprehensively across entire mammalian genomes, we developed a large-scale chromatin immunoprecipitation assay (ChIPSeq) based on direct ultrahigh-throughput DNA sequencing. This sequence census method was then used to map in vivo binding of the neuron-restrictive silencer factor (NRSF; also known as REST, for repressor element-1 silencing transcription factor) to 1946 locations in the human genome. The data display sharp resolution of binding position [+/-50 base pairs (bp)], which facilitated our finding motifs and allowed us to identify noncanonical NRSF-binding motifs. These ChIPSeq data also have high sensitivity and specificity [ROC (receiver operator characteristic) area >/= 0.96] and statistical confidence (P <10(-4)), properties that were important for inferring new candidate interactions. These include key transcription factors in the gene network that regulates pancreatic islet cell development.},
author = {Johnson, David S and Mortazavi, Ali and Myers, Richard M and Wold, Barbara},
doi = {10.1126/science.1141319},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/21\_Solexa.pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Algorithms,Amino Acid Motifs,Binding Sites,Chromatin Immunoprecipitation,DNA,DNA-Binding Proteins,DNA-Binding Proteins: chemistry,DNA-Binding Proteins: metabolism,DNA: metabolism,Gene Regulatory Networks,Genome, Human,Humans,Insulin-Secreting Cells,Insulin-Secreting Cells: cytology,Insulin-Secreting Cells: physiology,MicroRNAs,MicroRNAs: genetics,Neurons,Neurons: physiology,Promoter Regions, Genetic,Protein Binding,Repressor Proteins,Repressor Proteins: chemistry,Repressor Proteins: genetics,Repressor Proteins: metabolism,Sensitivity and Specificity,Sequence Analysis, DNA,Synaptic Transmission,T-Lymphocytes,T-Lymphocytes: metabolism,Transcription Factors,Transcription Factors: chemistry,Transcription Factors: genetics,Transcription Factors: metabolism,Transcription, Genetic,Zinc Fingers},
month = jun,
number = {5830},
pages = {1497--502},
pmid = {17540862},
title = {{Genome-wide mapping of in vivo protein-DNA interactions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17540862},
volume = {316},
year = {2007}
}
@article{Thampi2009,
abstract = {Bioinformatics is a new discipline that addresses the need to manage and interpret the data that in the past decade was massively generated by genomic research. This discipline represents the convergence of genomics, biotechnology and information technology, and encompasses analysis and interpretation of data, modeling of biological phenomena, and development of algorithms and statistics. This article presents an introduction to bioinformatics},
annote = {Gott yfirlit yfir BioInformatics},
author = {Thampi, Sabu M},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thampi - 2009 - Introduction to Bioinformatics.pdf:pdf;:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thampi - 2009 - Introduction to Bioinformatics.html:html},
journal = {0911.4230},
keywords = {Computer Science - Computational Engineering- Fina},
mendeley-tags = {Computer Science - Computational Engineering- Fina},
month = nov,
title = {{Introduction to Bioinformatics}},
url = {http://arxiv.org/abs/0911.4230 http://www.arxiv.org/pdf/0911.4230.pdf},
year = {2009}
}
@article{Metzker2010,
abstract = {Demand has never been greater for revolutionary technologies that deliver fast, inexpensive and accurate genome information. This challenge has catalysed the development of next-generation sequencing (NGS) technologies. The inexpensive production of large volumes of sequence data is the primary advantage over conventional methods. Here, I present a technical review of template preparation, sequencing and imaging, genome alignment and assembly approaches, and recent advances in current and near-term commercially available NGS instruments. I also outline the broad range of applications for NGS technologies, in addition to providing guidelines for platform selection to address biological questions of interest.},
author = {Metzker, Michael L},
institution = {Human Genome Sequencing Center and Department of Molecular \& Human Genetics, Baylor College of Medicine, Houston, Texas 77030, USA. mmetzker@bcm.edu},
journal = {Nature Reviews Genetics},
number = {1},
pages = {31--46},
pmid = {19997069},
publisher = {Nature Publishing Group},
title = {{Sequencing technologies - the next generation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19997069},
volume = {11},
year = {2010}
}
@article{Jiang2012,
abstract = {BACKGROUND:Sequence signatures, as defined by the frequencies of k-tuples (or k-mers, k-grams), have been used extensively to compare genomic sequences of individual organisms, to identify cis-regulatory modules, and to study the evolution of regulatory sequences. Recently many next-generation sequencing (NGS) read data sets of metagenomic samples from a variety of different environments have been generated. The assembly of these reads can be difficult and analysis methods based on mapping reads to genes or pathways are also restricted by the availability and completeness of existing databases. Sequence-signature-based methods, however, do not need the complete genomes or existing databases and thus, can potentially be very useful for the comparison of metagenomic samples using NGS read data. Still, the applications of sequence signature methods for the comparison of metagenomic samples have not been well studied.RESULTS:We studied several dissimilarity measures, including d2, d2* and d2S recently developed from our group, a measure (hereinafter noted as Hao) used in CVTree developed from Hao's group (Qi et al., 2004), measures based on relative di-, tri-, and tetra-nucleotide frequencies as in Willner et al. (2009), as well as standard lp measures between the frequency vectors, for the comparison of metagenomic samples using sequence signatures. We compared their performance using a series of extensive simulations and three real next-generation sequencing (NGS) metagenomic datasets: 39 fecal samples from 33 mammalian host species, 56 marine samples across the world, and 13 fecal samples from human individuals. Results showed that the dissimilarity measure d2S can achieve superior performance when comparing metagenomic samples by clustering them into different groups as well as recovering environmental gradients affecting microbial samples. New insights into the environmental factors affecting microbial compositions in metagenomic samples are obtained through the analyses. Our results show that sequence signatures of the mammalian gut are closely associated with diet and gut physiology of the mammals, and that sequence signatures of marine communities are closely related to location and temperature.CONCLUSIONS:Sequence signatures can successfully reveal major group and gradient relationships among metagenomic samples from NGS reads without alignment to reference databases. The d2S dissimilarity measure is a good choice in all application scenarios. The optimal choice of tuple size depends on sequencing depth, but it is quite robust within a range of choices for moderate sequencing depths.},
author = {Jiang, Bai and Song, Kai and Ren, Jie and Deng, Minghua and Sun, Fengzhu and Zhang, Xuegong},
doi = {10.1186/1471-2164-13-730},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - 2012 - Comparison of metagenomic samples using sequence signatures.pdf:pdf},
issn = {1471-2164},
journal = {BMC Genomics},
number = {1},
pages = {730},
title = {{Comparison of metagenomic samples using sequence signatures}},
url = {http://www.biomedcentral.com/1471-2164/13/730},
volume = {13},
year = {2012}
}
@article{Qin2010,
abstract = {To understand the impact of gut microbes on human health and well-being it is crucial to assess their genetic potential. Here we describe the Illumina-based metagenomic sequencing, assembly and characterization of 3.3 million non-redundant microbial genes, derived from 576.7 gigabases of sequence, from faecal samples of 124 European individuals. The gene set, \~{}150 times larger than the human gene complement, contains an overwhelming majority of the prevalent (more frequent) microbial genes of the cohort and probably includes a large proportion of the prevalent human intestinal microbial genes. The genes are largely shared among individuals of the cohort. Over 99\% of the genes are bacterial, indicating that the entire cohort harbours between 1,000 and 1,150 prevalent bacterial species and each individual at least 160 such species, which are also largely shared. We define and describe the minimal gut metagenome and the minimal gut bacterial genome in terms of functions present in all individuals and most bacteria, respectively.},
author = {Qin, Junjie and Li, Ruiqiang and Raes, Jeroen and Arumugam, Manimozhiyan and Burgdorf, Kristoffer Solvsten and Manichanh, Chaysavanh and Nielsen, Trine and Pons, Nicolas and Levenez, Florence and Yamada, Takuji and Mende, Daniel R. and Li, Junhua and Xu, Junming and Li, Shaochuan and Li, Dongfang and Cao, Jianjun and Wang, Bo and Liang, Huiqing and Zheng, Huisong and Xie, Yinlong and Tap, Julien and Lepage, Patricia and Bertalan, Marcelo and Batto, Jean-Michel and Hansen, Torben and Paslier, Denis Le and Linneberg, Allan and Nielsen, H. Bj\o rn and Pelletier, Eric and Renault, Pierre and Sicheritz-Ponten, Thomas and Turner, Keith and Zhu, Hongmei and Yu, Chang and Li, Shengting and Jian, Min and Zhou, Yan and Li, Yingrui and Zhang, Xiuqing and Li, Songgang and Qin, Nan and Yang, Huanming and Wang, Jian and Brunak, S\o ren and Dor\'{e}, Joel and Guarner, Francisco and Kristiansen, Karsten and Pedersen, Oluf and Parkhill, Julian and Weissenbach, Jean and Antolin, Maria and Artiguenave, Fran\c{c}ois and Blottiere, Herv\'{e} and Borruel, Natalia and Bruls, Thomas and Casellas, Francesc and Chervaux, Christian and Cultrone, Antonella and Delorme, Christine and Denariaz, G\'{e}rard and Dervyn, Rozenn and Forte, Miguel and Friss, Carsten and van de Guchte, Maarten and Guedon, Eric and Haimet, Florence and Jamet, Alexandre and Juste, Catherine and Kaci, Ghalia and Kleerebezem, Michiel and Knol, Jan and Kristensen, Michel and Layec, Severine and Roux, Karine Le and Leclerc, Marion and Maguin, Emmanuelle and Minardi, Raquel Melo and Oozeer, Raish and Rescigno, Maria and Sanchez, Nicolas and Tims, Sebastian and Torrejon, Toni and Varela, Encarna and de Vos, Willem and Winogradsky, Yohanan and Zoetendal, Erwin and Bork, Peer and Ehrlich, S. Dusko and Wang, Jun},
doi = {10.1038/nature08821},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qin et al. - 2010 - A human gut microbial gene catalogue established by metagenomic sequencing.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Computational Biology,DNA,Genomics,Nature,RNA,astronomy,astrophysics,biochemistry,bioinformatics,biology,biotechnology,cancer,cell cycle,cell signalling,climate change,development,developmental biology,drug discovery,earth science,ecology,environmental science,evolution,evolutionary biology,functional genomics,genetics,geophysics,immunology,interdisciplinary science,life,marine biology,materials science,medical research,medicine,metabolomics,molecular biology,molecular interactions,nanotechnology,neurobiology,neuroscience,palaeobiology,pharmacology,physics,proteomics,quantum physics,science,science news,science policy,signal transduction,structural biology,systems biology,transcriptomics},
language = {en},
mendeley-tags = {Computational Biology,DNA,Genomics,Nature,RNA,astronomy,astrophysics,biochemistry,bioinformatics,biology,biotechnology,cancer,cell cycle,cell signalling,climate change,development,developmental biology,drug discovery,earth science,ecology,environmental science,evolution,evolutionary biology,functional genomics,genetics,geophysics,immunology,interdisciplinary science,life,marine biology,materials science,medical research,medicine,metabolomics,molecular biology,molecular interactions,nanotechnology,neurobiology,neuroscience,palaeobiology,pharmacology,physics,proteomics,quantum physics,science,science news,science policy,signal transduction,structural biology,systems biology,transcriptomics},
month = mar,
number = {7285},
pages = {59--65},
title = {{A human gut microbial gene catalogue established by metagenomic sequencing}},
url = {http://www.nature.com/nature/journal/v464/n7285/full/nature08821.html http://www.nature.com/nature/journal/v464/n7285/pdf/nature08821.pdf},
volume = {464},
year = {2010}
}
@article{Margulies2005,
abstract = {The proliferation of large-scale DNA-sequencing projects in recent years has driven a search for alternative methods to reduce time and cost. Here we describe a scalable, highly parallel sequencing system with raw throughput significantly greater than that of state-of-the-art capillary electrophoresis instruments. The apparatus uses a novel fibre-optic slide of individual wells and is able to sequence 25 million bases, at 99\% or better accuracy, in one four-hour run. To achieve an approximately 100-fold increase in throughput over current Sanger sequencing technology, we have developed an emulsion method for DNA amplification and an instrument for sequencing by synthesis using a pyrosequencing protocol optimized for solid support and picolitre-scale volumes. Here we show the utility, throughput, accuracy and robustness of this system by shotgun sequencing and de novo assembly of the Mycoplasma genitalium genome with 96\% coverage at 99.96\% accuracy in one run of the machine.},
author = {Margulies, Marcel and Egholm, Michael and Altman, William E and Attiya, Said and Bader, Joel S and Bemben, Lisa a and Berka, Jan and Braverman, Michael S and Chen, Yi-Ju and Chen, Zhoutao and Dewell, Scott B and Du, Lei and Fierro, Joseph M and Gomes, Xavier V and Godwin, Brian C and He, Wen and Helgesen, Scott and Ho, Chun Heen and Ho, Chun He and Irzyk, Gerard P and Jando, Szilveszter C and Alenquer, Maria L I and Jarvie, Thomas P and Jirage, Kshama B and Kim, Jong-Bum and Knight, James R and Lanza, Janna R and Leamon, John H and Lefkowitz, Steven M and Lei, Ming and Li, Jing and Lohman, Kenton L and Lu, Hong and Makhijani, Vinod B and McDade, Keith E and McKenna, Michael P and Myers, Eugene W and Nickerson, Elizabeth and Nobile, John R and Plant, Ramona and Puc, Bernard P and Ronan, Michael T and Roth, George T and Sarkis, Gary J and Simons, Jan Fredrik and Simpson, John W and Srinivasan, Maithreyan and Tartaro, Karrie R and Tomasz, Alexander and Vogt, Kari a and Volkmer, Greg a and Wang, Shally H and Wang, Yong and Weiner, Michael P and Yu, Pengguang and Begley, Richard F and Rothberg, Jonathan M},
doi = {10.1038/nature03959},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/17\_454.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Electrophoresis, Capillary,Emulsions,Fiber Optic Technology,Genome, Bacterial,Genomics,Genomics: economics,Genomics: instrumentation,Microchemistry,Microchemistry: economics,Microchemistry: instrumentation,Mycoplasma genitalium,Mycoplasma genitalium: genetics,Polymerase Chain Reaction,Reproducibility of Results,Sensitivity and Specificity,Sequence Analysis, DNA,Sequence Analysis, DNA: economics,Sequence Analysis, DNA: instrumentation,Time Factors},
month = sep,
number = {7057},
pages = {376--80},
pmid = {16056220},
title = {{Genome sequencing in microfabricated high-density picolitre reactors.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1464427\&tool=pmcentrez\&rendertype=abstract},
volume = {437},
year = {2005}
}
@article{Sandberg2001,
abstract = {Bacterial genomes have diverged during evolution, resulting in clearcut differences in their nucleotide composition, such as their GC content. The analysis of complete sequences of bacterial genomes also reveals the presence of nonrandom sequence variation, manifest in the frequency profile of specific short oligonucleotides. These frequency profiles constitute highly specific genomic signatures. Based on these differences in oligonucleotide frequency between bacterial genomes, we investigated the possibility of predicting the genome of origin for a specific genomic sequence. To this end, we developed a na\"{\i}ve Bayesian classifier and systematically analyzed 28 eubacterial and archaeal genomes. We found that sequences as short as 400 bases could be correctly classified with an accuracy of 85\%. We then applied the classifier to the identification of horizontal gene transfer events in whole-genome sequences and demonstrated the validity of our approach by correctly predicting the transfer of both the superoxide dismutase (sodC) and the bioC gene from Haemophilus influenzae to Neisseria meningitis, correctly identifying both the donor and recipient species. We believe that this classification methodology could be a valuable tool in biodiversity studies.},
author = {Sandberg, Rickard and Winberg, G\"{o}sta and Br\"{a}nden, Carl-Ivar and Kaske, Alexander and Ernberg, Ingemar and C\"{o}ster, Joakim},
doi = {10.1101/gr.186401},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sandberg et al. - 2001 - Capturing Whole-Genome Characteristics in Short Sequences Using a Na\"{\i}ve Bayesian Classifier.pdf:pdf},
issn = {1088-9051},
journal = {Genome Research},
month = aug,
number = {8},
pages = {1404--1409},
title = {{Capturing Whole-Genome Characteristics in Short Sequences Using a Na\"{\i}ve Bayesian Classifier}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC311094/ http://www.ncbi.nlm.nih.gov/pmc/articles/PMC311094/pdf/X16.pdf},
volume = {11},
year = {2001}
}
@article{Gevers2012,
annote = {Testing, see if it works},
author = {Gevers, Dirk and Pop, Mihai and Schloss, Patrick D. and Huttenhower, Curtis},
doi = {10.1371/journal.pcbi.1002779},
editor = {Eisen, Jonathan A.},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gevers et al. - 2012 - Bioinformatics for the Human Microbiome Project.pdf:pdf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Biological data management,Biology,Computational Biology,Genetics and Genomics,Genomics,Metagenomics,Microbial ecology,Microbiology,Perspective,bioinformatics,microbiome},
mendeley-tags = {bioinformatics,microbiome},
month = nov,
number = {11},
pages = {e1002779},
publisher = {Public Library of Science},
title = {{Bioinformatics for the Human Microbiome Project}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002779},
volume = {8},
year = {2012}
}
@article{Flicek2009,
abstract = {The most important first step in understanding next-generation sequencing data is the initial alignment or assembly that determines whether an experiment has succeeded and provides a first glimpse into the results. In parallel with the growth of new sequencing technologies, several algorithms that align or assemble the large data output of today's sequencing machines have been developed. We discuss the current algorithmic approaches and future directions of these fundamental tools and provide specific examples for some commonly used tools.},
author = {Flicek, Paul and Birney, Ewan},
doi = {10.1038/nmeth.1376},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Flicek, Birney - 2009 - Sense from sequence reads methods for alignment and assembly.pdf:pdf},
issn = {1548-7091},
journal = {Nature Methods},
language = {en},
pages = {S6--S12},
shorttitle = {Sense from sequence reads},
title = {{Sense from sequence reads: methods for alignment and assembly}},
url = {http://www.nature.com/nmeth/journal/v6/n11s/abs/nmeth.1376.html},
volume = {6},
year = {2009}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:opt/mendeleydesktop/share/doc/mendeleydesktop/FAQ.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Yang2010,
abstract = {With the rapid development of genome sequencing techniques, traditional research methods based on the isolation and cultivation of microorganisms are being gradually replaced by metagenomics, which is also known as environmental genomics. The first step, which is still a major bottleneck, of metagenomics is the taxonomic characterization of DNA fragments (reads) resulting from sequencing a sample of mixed species. This step is usually referred as "binning". Existing binning methods are based on supervised or semi-supervised approaches which rely heavily on reference genomes of known microorganisms and phylogenetic marker genes. Due to the limited availability of reference genomes and the bias and instability of marker genes, existing binning methods may not be applicable in many cases.},
author = {Yang, Bin and Peng, Yu and Leung, Henry Chi-Ming and Yiu, Siu-Ming and Chen, Jing-Chi and Chin, Francis Yuk-Lun},
doi = {10.1186/1471-2105-11-S2-S5},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2010 - Unsupervised binning of environmental genomic fragments based on an error robust selection of l-mers(3).pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Algorithms,Bacterial,Bacterial: genetics,Cluster Analysis,DNA,DNA: chemistry,DNA: methods,Data Mining,Data Mining: methods,Databases,Environmental Microbiology,Escherichia coli,Escherichia coli: genetics,Genetic,Genome,Lactobacillus,Lactobacillus: genetics,Metagenomics,Metagenomics: methods,Sequence Analysis},
language = {en},
month = jan,
pages = {S5},
pmid = {20406503},
title = {{Unsupervised binning of environmental genomic fragments based on an error robust selection of l-mers.}},
url = {http://europepmc.org/articles/PMC3165929},
volume = {11 Suppl 2},
year = {2010}
}
@article{Kennedy2003,
abstract = {Genetic studies aimed at understanding the molecular basis of complex human phenotypes require the genotyping of many thousands of single-nucleotide polymorphisms (SNPs) across large numbers of individuals. Public efforts have so far identified over two million common human SNPs; however, the scoring of these SNPs is labor-intensive and requires a substantial amount of automation. Here we describe a simple but effective approach, termed whole-genome sampling analysis (WGSA), for genotyping thousands of SNPs simultaneously in a complex DNA sample without locus-specific primers or automation. Our method amplifies highly reproducible fractions of the genome across multiple DNA samples and calls genotypes at >99\% accuracy. We rapidly genotyped 14,548 SNPs in three different human populations and identified a subset of them with significant allele frequency differences between groups. We also determined the ancestral allele for 8,386 SNPs by genotyping chimpanzee and gorilla DNA. WGSA is highly scaleable and enables the creation of ultrahigh density SNP maps for use in genetic studies.},
author = {Kennedy, Giulia C and Matsuzaki, Hajime and Dong, Shoulian and Liu, Wei-min and Huang, Jing and Liu, Guoying and Su, Xing and Cao, Manqiu and Chen, Wenwei and Zhang, Jane and Liu, Weiwei and Yang, Geoffrey and Di, Xiaojun and Ryder, Thomas and He, Zhijun and Surti, Urvashi and Phillips, Michael S and Boyce-Jacino, Michael T and Fodor, Stephen P a and Jones, Keith W},
doi = {10.1038/nbt869},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/11\_Affy\_Whole.pdf:pdf},
issn = {1087-0156},
journal = {Nature biotechnology},
keywords = {Algorithms,Base Sequence,DNA,DNA: chemistry,DNA: genetics,Gene Expression Profiling,Gene Expression Profiling: methods,Gene Frequency,Gene Frequency: genetics,Genome, Human,Genotype,Humans,Molecular Sequence Data,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Polymorphism, Single Nucleotide,Polymorphism, Single Nucleotide: genetics,Reproducibility of Results,Sensitivity and Specificity,Sequence Alignment,Sequence Alignment: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Sequence Homology, Nucleic Acid},
month = oct,
number = {10},
pages = {1233--7},
pmid = {12960966},
title = {{Large-scale genotyping of complex DNA.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12960966},
volume = {21},
year = {2003}
}
@article{Korlach2010,
abstract = {Pacific Biosciences has developed a method for real-time sequencing of single DNA molecules (Eid et al., 2009), with intrinsic sequencing rates of several bases per second and read lengths into the kilobase range. Conceptually, this sequencing approach is based on eavesdropping on the activity of DNA polymerase carrying out template-directed DNA polymerization. Performed in a highly parallel operational mode, sequential base additions catalyzed by each polymerase are detected with terminal phosphate-linked, fluorescence-labeled nucleotides. This chapter will first outline the principle of this single-molecule, real-time (SMRT) DNA sequencing method, followed by descriptions of its underlying components and typical sequencing run conditions. Two examples are provided which illustrate that, in addition to the DNA sequence, the dynamics of DNA polymerization from each enzyme molecules is directly accessible: the determination of base-specific kinetic parameters from single-molecule sequencing reads, and the characterization of DNA synthesis rate heterogeneities.},
author = {Korlach, Jonas and Bjornson, Keith P and Chaudhuri, Bidhan P and Cicero, Ronald L and Flusberg, Benjamin a and Gray, Jeremy J and Holden, David and Saxena, Ravi and Wegener, Jeffrey and Turner, Stephen W},
doi = {10.1016/S0076-6879(10)72001-2},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/24\_PacBio.pdf:pdf},
issn = {1557-7988},
journal = {Methods in enzymology},
keywords = {Animals,Base Sequence,DNA,DNA-Directed DNA Polymerase,DNA-Directed DNA Polymerase: metabolism,DNA: chemistry,DNA: genetics,DNA: metabolism,Fluorescent Dyes,Fluorescent Dyes: chemistry,Fluorescent Dyes: metabolism,Molecular Structure,Nucleotides,Nucleotides: chemistry,Sequence Analysis, DNA,Sequence Analysis, DNA: instrumentation,Sequence Analysis, DNA: methods},
month = jan,
number = {January},
pages = {431--55},
pmid = {20580975},
title = {{Real-time DNA sequencing from single polymerase molecules.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20580975},
volume = {472},
year = {2010}
}
@article{Holmes2012,
abstract = {We introduce Dirichlet multinomial mixtures (DMM) for the probabilistic modelling of microbial metagenomics data. This data can be represented as a frequency matrix giving the number of times each taxa is observed in each sample. The samples have different size, and the matrix is sparse, as communities are diverse and skewed to rare taxa. Most methods used previously to classify or cluster samples have ignored these features. We describe each community by a vector of taxa probabilities. These vectors are generated from one of a finite number of Dirichlet mixture components each with different hyperparameters. Observed samples are generated through multinomial sampling. The mixture components cluster communities into distinct ‘metacommunities’, and, hence, determine envirotypes or enterotypes, groups of communities with a similar composition. The model can also deduce the impact of a treatment and be used for classification. We wrote software for the fitting of DMM models using the ‘evidence framework’ (http://code.google.com/p/microbedmm/). This includes the Laplace approximation of the model evidence. We applied the DMM model to human gut microbe genera frequencies from Obese and Lean twins. From the model evidence four clusters fit this data best. Two clusters were dominated by Bacteroides and were homogenous; two had a more variable community composition. We could not find a significant impact of body mass on community structure. However, Obese twins were more likely to derive from the high variance clusters. We propose that obesity is not associated with a distinct microbiota but increases the chance that an individual derives from a disturbed enterotype. This is an example of the ‘Anna Karenina principle (AKP)’ applied to microbial communities: disturbed states having many more configurations than undisturbed. We verify this by showing that in a study of inflammatory bowel disease (IBD) phenotypes, ileal Crohn's disease (ICD) is associated with a more variable community.},
annote = {one on Dirichlet for clustering samples based on their microbiota composition.},
author = {Holmes, Ian and Harris, Keith and Quince, Christopher},
doi = {10.1371/journal.pone.0030126},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holmes, Harris, Quince - 2012 - Dirichlet Multinomial Mixtures Generative Models for Microbial Metagenomics.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = feb,
number = {2},
shorttitle = {Dirichlet Multinomial Mixtures},
title = {{Dirichlet Multinomial Mixtures: Generative Models for Microbial Metagenomics}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3272020/ http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3272020/pdf/pone.0030126.pdf},
volume = {7},
year = {2012}
}
@article{Pettersson2009,
abstract = {Advancements in the field of DNA sequencing are changing the scientific horizon and promising an era of personalized medicine for elevated human health. Although platforms are improving at the rate of Moore's Law, thereby reducing the sequencing costs by a factor of two or three each year, we find ourselves at a point in history where individual genomes are starting to appear but where the cost is still too high for routine sequencing of whole genomes. These needs will be met by miniaturized and parallelized platforms that allow a lower sample and template consumption thereby increasing speed and reducing costs. Current massively parallel, state-of-the-art systems are providing significantly improved throughput over Sanger systems and future single-molecule approaches will continue the exponential improvements in the field.},
author = {Pettersson, Erik and Lundeberg, Joakim and Ahmadian, Afshin},
doi = {10.1016/j.ygeno.2008.10.003},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/16\_Review\_Pettersson.pdf:pdf},
issn = {1089-8646},
journal = {Genomics},
keywords = {Base Sequence,DNA,DNA: analysis,DNA: genetics,Genome, Human,Genomics,Genomics: trends,Humans,Models, Biological,Sequence Analysis, DNA,Sequence Analysis, DNA: economics,Sequence Analysis, DNA: methods,Sequence Analysis, DNA: trends},
month = feb,
number = {2},
pages = {105--11},
pmid = {18992322},
title = {{Generations of sequencing technologies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18992322},
volume = {93},
year = {2009}
}
@article{Mardis2008,
abstract = {If one accepts that the fundamental pursuit of genetics is to determine the genotypes that explain phenotypes, the meteoric increase of DNA sequence information applied toward that pursuit has nowhere to go but up. The recent introduction of instruments capable of producing millions of DNA sequence reads in a single run is rapidly changing the landscape of genetics, providing the ability to answer questions with heretofore unimaginable speed. These technologies will provide an inexpensive, genome-wide sequence readout as an endpoint to applications ranging from chromatin immunoprecipitation, mutation mapping and polymorphism discovery to noncoding RNA discovery. Here I survey next-generation sequencing technologies and consider how they can provide a more complete picture of how the genome shapes the organism.},
author = {Mardis, Elaine R},
doi = {10.1016/j.tig.2007.12.007},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/15\_2Review\_Mardis.pdf:pdf},
issn = {0168-9525},
journal = {Trends in genetics : TIG},
keywords = {Animals,Forecasting,Genetics,Genetics: trends,Humans,Sequence Analysis, DNA},
month = mar,
number = {3},
pages = {133--41},
pmid = {18262675},
title = {{The impact of next-generation sequencing technology on genetics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18262675},
volume = {24},
year = {2008}
}
@article{Tyson2004,
abstract = {Nature is the international weekly journal of science: a magazine style journal that publishes full-length research papers in all disciplines of science, as well as News and Views, reviews, news, features, commentaries, web focuses and more, covering all branches of science and how science impacts upon all aspects of society and life.},
author = {Tyson, Gene W. and Chapman, Jarrod and Hugenholtz, Philip and Allen, Eric E. and Ram, Rachna J. and Richardson, Paul M. and Solovyev, Victor V. and Rubin, Edward M. and Rokhsar, Daniel S. and Banfield, Jillian F.},
doi = {10.1038/nature02340},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tyson et al. - 2004 - Community structure and metabolism through reconstruction of microbial genomes from the environment.pdf:pdf;:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tyson et al. - 2004 - Community structure and metabolism through reconstruction of microbial genomes from the environment.html:html},
journal = {Nature},
keywords = {Computational Biology,DNA,Genomics,Nature,RNA,astronomy,astrophysics,biochemistry,bioinformatics,biology,biotechnology,cancer,cell cycle,cell signalling,climate change,development,developmental biology,drug discovery,earth science,ecology,environmental science,evolution,evolutionary biology,functional genomics,genetics,geophysics,immunology,interdisciplinary science,life,marine biology,materials science,medical research,medicine,metabolomics,molecular biology,molecular interactions,nanotechnology,neurobiology,neuroscience,palaeobiology,pharmacology,physics,proteomics,quantum physics,science,science news,science policy,signal transduction,structural biology,systems biology,transcriptomics},
mendeley-tags = {Computational Biology,DNA,Genomics,Nature,RNA,astronomy,astrophysics,biochemistry,bioinformatics,biology,biotechnology,cancer,cell cycle,cell signalling,climate change,development,developmental biology,drug discovery,earth science,ecology,environmental science,evolution,evolutionary biology,functional genomics,genetics,geophysics,immunology,interdisciplinary science,life,marine biology,materials science,medical research,medicine,metabolomics,molecular biology,molecular interactions,nanotechnology,neurobiology,neuroscience,palaeobiology,pharmacology,physics,proteomics,quantum physics,science,science news,science policy,signal transduction,structural biology,systems biology,transcriptomics},
month = feb,
number = {6978},
pages = {37},
title = {{Community structure and metabolism through reconstruction of microbial genomes from the environment}},
url = {https://vpn.lan.kth.se/+CSCO+c0756767633A2F2F6A6A6A2E616E676865722E70627A++/nature/journal/v428/n6978/full/nature02340.html},
volume = {428},
year = {2004}
}
@article{Waltemath2013,
abstract = {Motivation: Only models that are accessible to researchers can be reused. As computational models evolve over time, a number of different but related versions of a model exist. Consequently, tools are required to manage not only well-curated models but also their associated versions. Results: In this work we discuss conceptual requirements for model version control. Focusing on XML formats such as SBML and CellML, we present methods for the identification and explanation of differences, and for the justification of changes between model versions. In consequence, researchers can reflect upon these changes, which in turn has considerable value for the development of new models. The implementation of model version control will therefore foster the exploration of published models and increase their reusability. Availability: We have implemented the proposed methods in a software library called BiVeS. It is freely available at http://sems.uni-rostock.de/bives/. BiVeS is also integrated in the online application BudHat which is available for testing at http://sems.uni-rostock.de/budhat/1. Contact: dagmar.waltemath@uni-rostock.de},
author = {Waltemath, D. and Henkel, R. and Halke, R. and Scharm, M. and Wolkenhauer, O.},
doi = {10.1093/bioinformatics/btt018},
file = {:home/binni/Downloads/Bioinformatics-2013-Waltemath-bioinformatics\_btt018.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
keywords = {models,version control},
mendeley-tags = {models,version control},
month = jan,
pages = {btt018--},
title = {{Improving the reuse of computational models through version control}},
url = {http://bioinformatics.oxfordjournals.org/content/early/2013/01/18/bioinformatics.btt018.abstract},
year = {2013}
}
@article{Bustamam2011a,
abstract = {Markov clustering (MCL) is becoming a key algorithm within bioinformatics for determining clusters in networks. However, with increasing vast amounts of data on biological networks, performance and scalability issues are becoming a critical limiting factor in applications. Meanwhile, GPU computing, which uses CUDA tool for implementing a massively parallel computing environment in the GPU card, is becoming a very powerful, efficient and low cost option to achieve substantial performance gains over CPU approaches. The use of on-chip memory on the GPU is efficiently lowering the latency time thus circumventing a major issue in other parallel computing environments, such as MPI. We introduce a very fast Markov clustering algorithm using CUDA (CUDA-MCL) to perform parallel sparse matrix-matrix computations and parallel sparse Markov matrix normalizations, which are at the heart of MCL. We utilized ELLPACK-R sparse format to allow the effective and fine-grain massively parallel processing to cope with the sparse nature of interaction networks datasets in bioinformatics applications. As the results show, CUDA-MCL is significantly faster than the original MCL running on CPU. Thus, large-scale parallel computation on off-the-shelf desktop-machines, that were previously only possible on supercomputing architectures, can significantly change the way bioinformaticians and biologists deal with their data.},
author = {Bustamam, Alhadi and Burrage, Kevin and Hamilton, Nicholas A},
doi = {10.1109/TCBB.2011.68},
file = {:home/binni/Downloads/06171972.pdf:pdf},
issn = {15579964},
journal = {IEEEACM transactions on computational biology and bioinformatics IEEE ACM},
number = {3},
pages = {679--692},
pmid = {21483031},
title = {{Fast Parallel Markov Clustering in Bioinformatics using Massively Parallel Computing on GPU with CUDA and ELLPACK-R Sparse Format.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21483031},
volume = {9},
year = {2011}
}
@misc{Olman2009a,
abstract = {Large sets of bioinformatical data provide a challenge in time consumption while solving the cluster identification problem, and that is why a parallel algorithm is so needed for identifying dense clusters in a noisy background. Our algorithm works on a graph representation of the data set to be analyzed. It identifies clusters through the identification of densely intraconnected subgraphs. We have employed a minimum spanning tree (MST) representation of the graph and solve the cluster identification problem using this representation. The computational bottleneck of our algorithm is the construction of an MST of a graph, for which a parallel algorithm is employed. Our high-level strategy for the parallel MST construction algorithm is to first partition the graph, then construct MSTs for the partitioned subgraphs and auxiliary bipartite graphs based on the subgraphs, and finally merge these MSTs to derive an MST of the original graph. The computational results indicate that when running on 150 CPUs, our algorithm can solve a cluster identification problem on a data set with 1,000,000 data points almost 100 times faster than on single CPU, indicating that this program is capable of handling very large data clustering problems in an efficient manner. We have implemented the clustering algorithm as the software CLUMP.},
author = {Olman, V and Mao, Fenglou Mao Fenglou and Wu, Hongwei Wu Hongwei and Xu, Ying Xu Ying},
booktitle = {IEEEACM Transactions on Computational Biology and Bioinformatics},
doi = {10.1109/TCBB.2007.70272},
file = {:home/binni/Downloads/04524229.pdf:pdf},
issn = {15455963},
keywords = {bioinformatics (genome protein) databases,clustering,clustering algorithm,genome application,parallel processing.,pattern recognition},
number = {2},
pages = {344--52},
publisher = {IEEE Computer Society},
title = {{Parallel Clustering Algorithm for Large Data Sets with Applications in Bioinformatics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19407357},
volume = {6},
year = {2009}
}
@article{Ahmadian2000,
abstract = {There is a growing demand for high-throughput methods for analysis of single-nucleotide polymorphic (SNP) positions. Here, we have evaluated a novel sequencing approach, pyrosequencing, for such purposes. Pyrosequencing is a sequencing-by-synthesis method in which a cascade of enzymatic reactions yields detectable light, which is proportional to incorporated nucleotides. One feature of typing SNPs with pyrosequencing is that each allelic variant will give a unique sequence compared to the two other variants. These variants can easily be distinguished by a pattern recognition software. The software displays the allelic alternatives and allows for direct comparison with the pyrosequencing raw data. For optimal determination of SNPs, various protocols of nucleotide dispensing order were investigated. Here, we demonstrate that typing of SNPs can efficiently be performed by pyrosequencing using an automated system for parallel analysis of 96 samples in approximately 5 min, suitable for large-scale screening and typing of SNPs.},
author = {Ahmadian, a and Gharizadeh, B and Gustafsson, a C and Sterky, F and Nyr\'{e}n, P and Uhl\'{e}n, M and Lundeberg, J},
doi = {10.1006/abio.2000.4493},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/5\_SNP\_Pyro.pdf:pdf},
issn = {0003-2697},
journal = {Analytical biochemistry},
keywords = {Base Sequence,Codon,DNA Primers,Humans,Loss of Heterozygosity,Polymerase Chain Reaction,Polymorphism, Single Nucleotide,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = apr,
number = {1},
pages = {103--10},
pmid = {10805527},
title = {{Single-nucleotide polymorphism analysis by pyrosequencing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10805527},
volume = {280},
year = {2000}
}
@book{Stroustrup2008,
author = {Stroustrup, B},
booktitle = {Chemistry \& \ldots},
file = {:home/binni/Dropbox/PDFbooks/progr\_princ\_pract\_cpp.pdf:pdf},
isbn = {978-0-321-54372-1},
title = {{Programming: principles and practice using C++}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract http://dl.acm.org/citation.cfm?id=1496384},
year = {2008}
}
@article{Wang2009,
abstract = {RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes.},
author = {Wang, Zhong and Gerstein, Mark and Snyder, Michael},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Gerstein, Snyder - 2009 - RNA-Seq a revolutionary tool for transcriptomics.pdf:pdf},
institution = {Department of Molecular, Cellular and Developmental Biology, Yale University, 219 Prospect Street, New Haven, Connecticut 06520, USA.},
journal = {Nature Reviews Genetics},
keywords = {animals,base sequence,chromosome mapping,exons,gene expression profiling,gene expression profiling methods,genetic,humans,models,molecular sequence data,rna,rna analysis,rna methods,sequence analysis,transcription},
number = {1},
pages = {57--63},
publisher = {Nature Publishing Group},
title = {{RNA-Seq: a revolutionary tool for transcriptomics.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2949280\&tool=pmcentrez\&rendertype=abstract},
volume = {10},
year = {2009}
}
@article{Wang2012_4,
abstract = {Next-generation sequencing (NGS) technologies allow the sequencing of microbial communities directly from the environment without prior culturing. The output of environmental DNA sequencing consists of many reads from genomes of different unknown species, making the clustering together reads from the same (or similar) species (also known as binning) a crucial step. The difficulties of the binning problem are due to the following four factors: (1) the lack of reference genomes; (2) uneven abundance ratio of species; (3) short NGS reads; and (4) a large number of species (can be more than a hundred). None of the existing binning tools can handle all four factors. No tools, including both AbundanceBin and MetaCluster 3.0, have demonstrated reasonable performance on a sample with more than 20 species. In this article, we introduce MetaCluster 4.0, an unsupervised binning algorithm that can accurately (with about 80\% precision and sensitivity in all cases and at least 90\% in some cases) and efficiently bin short reads with varying abundance ratios and is able to handle datasets with 100 species. The novelty of MetaCluster 4.0 stems from solving a few important problems: how to divide reads into groups by a probabilistic approach, how to estimate the 4-mer distribution of each group, how to estimate the number of species, and how to modify MetaCluster 3.0 to handle a large number of species. We show that Meta Cluster 4.0 is effective for both simulated and real datasets. Supplementary Material is available at www.liebertonline.com/cmb.},
author = {Wang, Yi and Leung, Henry C M and Yiu, S M and Chin, Francis Y L},
doi = {10.1089/cmb.2011.0276},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2012 - MetaCluster 4.0 a novel binning algorithm for NGS reads and huge number of species(2).pdf:pdf},
issn = {1557-8666},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {Algorithms,Bacteria,Bacteria: genetics,Bacterial,Base Sequence,Cluster Analysis,DNA,DNA: methods,Data Interpretation,Genome,High-Throughput Nucleotide Sequencing,Models,Sequence Analysis,Software,Statistical},
month = feb,
number = {2},
pages = {241--9},
pmid = {22300323},
title = {{MetaCluster 4.0: a novel binning algorithm for NGS reads and huge number of species.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22300323},
volume = {19},
year = {2012}
}
@article{Hugenholtz2008,
author = {Hugenholtz, Philip and Tyson, Gene W.},
doi = {10.1038/455481a},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hugenholtz, Tyson - 2008 - Q \& A Metagenomics(2).pdf:pdf;:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hugenholtz, Tyson - 2008 - Microbiology Metagenomics.html:html},
issn = {0028-0836, 1476-4687},
journal = {Nature},
month = sep,
number = {7212},
pages = {481--483},
shorttitle = {Microbiology},
title = {{Microbiology: Metagenomics}},
url = {https://vpn.lan.kth.se/+CSCO+00756767633A2F2F6A6A6A2E616E676865722E70627A++/nature/journal/v455/n7212/full/455481a.html},
volume = {455},
year = {2008}
}
@article{Prabhakara2012,
abstract = {A major challenge facing metagenomics is the development of tools for the characterization of functional and taxonomic content of vast amounts of short metagenome reads. The efficacy of clustering methods depends on the number of reads in the dataset, the read length and relative abundances of source genomes in the microbial community. In this paper, we formulate an unsupervised naive Bayes multispecies, multidimensional mixture model for reads from a metagenome. We use the proposed model to cluster metagenomic reads by their species of origin and to characterize the abundance of each species. We model the distribution of word counts along a genome as a Gaussian for shorter, frequent words and as a Poisson for longer words that are rare. We employ either a mixture of Gaussians or mixture of Poissons to model reads within each bin. Further, we handle the high-dimensionality and sparsity associated with the data, by grouping the set of words comprising the reads, resulting in a two-way mixture model. Finally, we demonstrate the accuracy and applicability of this method on simulated and real metagenomes. Our method can accurately cluster reads as short as 100 bps and is robust to varying abundances, divergences and read lengths.},
author = {Prabhakara, Shruthi and Acharya, Raj},
doi = {10.1155/2012/153647},
file = {:home/binni/Downloads/JBB2012-153647.pdf:pdf},
issn = {1110-7251},
journal = {Journal of biomedicine \& biotechnology},
keywords = {Algorithms,Bacterial,Cluster Analysis,Computer Simulation,Databases,Genetic,Genome,Metagenomics,Metagenomics: methods,Models},
month = jan,
pages = {153647},
pmid = {22577288},
title = {{Unsupervised two-way clustering of metagenomic sequences.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3336163\&tool=pmcentrez\&rendertype=abstract},
volume = {2012},
year = {2012}
}
@article{Fan2003,
author = {Fan, J B and Oliphant, a and Shen, R and Kermani, B G and Garcia, F and Gunderson, K L and Hansen, M and Steemers, F and Butler, S L and Deloukas, P and Galver, L and Hunt, S and McBride, C and Bibikova, M and Rubano, T and Chen, J and Wickham, E and Doucet, D and Chang, W and Campbell, D and Zhang, B and Kruglyak, S and Bentley, D and Haas, J and Rigault, P and Zhou, L and Stuelpnagel, J and Chee, M S},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/9\_Golden\_Gate.pdf:pdf},
isbn = {0879697091},
issn = {0091-7451},
journal = {Cold Spring Harbor symposia on quantitative biology},
keywords = {Alleles,Data Interpretation, Statistical,Genetic Techniques,Genetic Techniques: instrumentation,Genetic Techniques: standards,Genetic Techniques: statistics \& numerical data,Genetic Variation,Genotype,Humans,Polymerase Chain Reaction,Polymorphism, Single Nucleotide,Quality Control,RNA, Messenger,RNA, Messenger: genetics},
month = jan,
pages = {69--78},
pmid = {15338605},
title = {{Highly parallel SNP genotyping.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3074135\&tool=pmcentrez\&rendertype=abstract},
volume = {68},
year = {2003}
}
@article{Quince2011,
abstract = {Background
In many environmental genomics applications a homologous region of DNA from a diverse sample is first amplified by PCR and then sequenced. The next generation sequencing technology, 454 pyrosequencing, has allowed much larger read numbers from PCR amplicons than ever before. This has revolutionised the study of microbial diversity as it is now possible to sequence a substantial fraction of the 16S rRNA genes in a community. However, there is a growing realisation that because of the large read numbers and the lack of consensus sequences it is vital to distinguish noise from true sequence diversity in this data. Otherwise this leads to inflated estimates of the number of types or operational taxonomic units (OTUs) present. Three sources of error are important: sequencing error, PCR single base substitutions and PCR chimeras. We present AmpliconNoise, a development of the PyroNoise algorithm that is capable of separately removing 454 sequencing errors and PCR single base errors. We also introduce a novel chimera removal program, Perseus, that exploits the sequence abundances associated with pyrosequencing data. We use data sets where samples of known diversity have been amplified and sequenced to quantify the effect of each of the sources of error on OTU inflation and to validate these algorithms.

Results
AmpliconNoise outperforms alternative algorithms substantially reducing per base error rates for both the GS FLX and latest Titanium protocol. All three sources of error lead to inflation of diversity estimates. In particular, chimera formation has a hitherto unrealised importance which varies according to amplification protocol. We show that AmpliconNoise allows accurate estimates of OTU number. Just as importantly AmpliconNoise generates the right OTUs even at low sequence differences. We demonstrate that Perseus has very high sensitivity, able to find 99\% of chimeras, which is critical when these are present at high frequencies.

Conclusions
AmpliconNoise followed by Perseus is a very effective pipeline for the removal of noise. In addition the principles behind the algorithms, the inference of true sequences using Expectation-Maximization (EM), and the treatment of chimera detection as a classification or 'supervised learning' problem, will be equally applicable to new sequencing technologies as they appear.},
annote = {One of Chris' articles where he uses EM to denoise 454 reads},
author = {Quince, Christopher and Lanzen, Anders and Davenport, Russell J and Turnbaugh, Peter J},
doi = {10.1186/1471-2105-12-38},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quince et al. - 2011 - Removing Noise From Pyrosequenced Amplicons.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
month = jan,
pages = {38},
title = {{Removing Noise From Pyrosequenced Amplicons}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3045300/ http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3045300/pdf/1471-2105-12-38.pdf},
volume = {12},
year = {2011}
}
@article{Leung2011,
abstract = {With the rapid development of next-generation sequencing techniques, metagenomics, also known as environmental genomics, has emerged as an exciting research area that enables us to analyze the microbial environment in which we live. An important step for metagenomic data analysis is the identification and taxonomic characterization of DNA fragments (reads or contigs) resulting from sequencing a sample of mixed species. This step is referred to as 'binning'. Binning algorithms that are based on sequence similarity and sequence composition markers rely heavily on the reference genomes of known microorganisms or phylogenetic markers. Due to the limited availability of reference genomes and the bias and low availability of markers, these algorithms may not be applicable in all cases. Unsupervised binning algorithms which can handle fragments from unknown species provide an alternative approach. However, existing unsupervised binning algorithms only work on datasets either with balanced species abundance ratios or rather different abundance ratios, but not both.},
author = {Leung, Henry C M and Yiu, S M and Yang, Bin and Peng, Yu and Wang, Yi and Liu, Zhihua and Chen, Jingchi and Qin, Junjie and Li, Ruiqiang and Chin, Francis Y L},
doi = {10.1093/bioinformatics/btr186},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leung et al. - 2011 - A robust and accurate binning algorithm for metagenomic sequences with arbitrary species abundance ratio(2).pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Cluster Analysis,DNA,Metagenomics,Metagenomics: methods,Sequence Analysis},
month = jun,
number = {11},
pages = {1489--95},
pmid = {21493653},
title = {{A robust and accurate binning algorithm for metagenomic sequences with arbitrary species abundance ratio.}},
url = {http://bioinformatics.oxfordjournals.org/content/27/11/1489.long},
volume = {27},
year = {2011}
}
@misc{Zhang2011a,
abstract = {Clustering is one of the most popular methods for data analysis, which is prevalent in many disciplines such as image segmentation, bioinformatics, pattern recognition and statistics etc. The most popular and simplest clustering algorithm is K-means because of its easy implementation, simplicity, efficiency and empirical success. However, the real-world applications produce huge volumes of data, thus, how to efficiently handle of these data in an important mining task has been a challenging and significant issue. In addition, MPI (Message Passing Interface) as a programming model of message passing presents high performances, scalability and portability. Motivated by this, a parallel K-means clustering algorithm with MPI, called MKmeans, is proposed in this paper. The algorithm enables applying the clustering algorithm effectively in the parallel environment. Experimental study demonstrates that MKmeans is relatively stable and portable, and it performs with low overhead of time on large volumes of data sets.},
author = {Zhang, Jing and Wu, Gongqing and Hu, Xuegang and Li, Shiying and Hao, Shuilong},
booktitle = {2011 Fourth International Symposium on Parallel Architectures Algorithms and Programming},
doi = {10.1109/PAAP.2011.17},
file = {:home/binni/Downloads/art\%3A10.1007\%2Fs11227-006-0002-7.pdf:pdf},
isbn = {9781457718083},
keywords = {clustering,k means algorithm,mpi,parallel computing},
number = {1},
pages = {60--64},
publisher = {IEEE},
title = {{A Parallel K-Means Clustering Algorithm with MPI}},
url = {http://www.springerlink.com/index/10.1007/s11227-006-0002-7},
volume = {39},
year = {2011}
}
@article{Noble2009,
author = {Noble, William Stafford},
doi = {10.1371/journal.pcbi.1000424},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noble - 2009 - A Quick Guide to Organizing Computational Biology Projects.pdf:pdf;:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noble - 2009 - A Quick Guide to Organizing Computational Biology Projects.html:html},
journal = {PLoS Comput Biol},
month = jul,
number = {7},
pages = {e1000424},
title = {{A Quick Guide to Organizing Computational Biology Projects}},
url = {http://dx.doi.org/10.1371/journal.pcbi.1000424 http://www.ploscompbiol.org/article/fetchObjectAttachment.action?uri=info:doi/10.1371/journal.pcbi.1000424\&representation=PDF http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1000424},
volume = {5},
year = {2009}
}
@article{Strous2012a,
abstract = {So far, microbial physiology has dedicated itself mainly to pure cultures. In nature, cross feeding and competition are important aspects of microbial physiology and these can only be addressed by studying complete communities such as enrichment cultures. Metagenomic sequencing is a powerful tool to characterize such mixed cultures. In the analysis of metagenomic data, well established algorithms exist for the assembly of short reads into contigs and for the annotation of predicted genes. However, the binning of the assembled contigs or unassembled reads is still a major bottleneck and required to understand how the overall metabolism is partitioned over different community members. Binning consists of the clustering of contigs or reads that apparently originate from the same source population. In the present study eight metagenomic samples from the same habitat, a laboratory enrichment culture, were sequenced. Each sample contained 13-23 Mb of assembled contigs and up to eight abundant populations. Binning was attempted with existing methods but they were found to produce poor results, were slow, dependent on non-standard platforms or produced errors. A new binning procedure was developed based on multivariate statistics of tetranucleotide frequencies combined with the use of interpolated Markov models. Its performance was evaluated by comparison of the results between samples with BLAST and in comparison to existing algorithms for four publicly available metagenomes and one previously published artificial metagenome. The accuracy of the new approach was comparable or higher than existing methods. Further, it was up to a 100 times faster. It was implemented in Java Swing as a complete open source graphical binning application available for download and further development (http://sourceforge.net/projects/metawatt).},
author = {Strous, Marc and Kraft, Beate and Bisdorf, Regina and Tegetmeyer, Halina E.},
doi = {10.3389/fmicb.2012.00410},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strous et al. - 2012 - The Binning of Metagenomic Contigs for Microbial Physiology of Mixed Cultures(2).pdf:pdf},
issn = {1664-302X},
journal = {Frontiers in Microbiology},
month = jan,
pages = {410},
pmid = {23227024},
title = {{The Binning of Metagenomic Contigs for Microbial Physiology of Mixed Cultures}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3514610\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2012}
}
@article{Shendure2008,
author = {Shendure, Jay},
doi = {10.1038/nmeth0708-585},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/22\_Beginning\_of\_the\_end.pdf:pdf},
issn = {1548-7105},
journal = {Nature methods},
keywords = {Animals,Gene Expression Profiling,Gene Expression Profiling: methods,Gene Expression Profiling: trends,Humans,Nucleic Acid Hybridization,Nucleic Acid Hybridization: methods,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Oligonucleotide Array Sequence Analysis: trends,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Sequence Analysis, DNA: trends,Sequence Analysis, RNA,Sequence Analysis, RNA: methods,Sequence Analysis, RNA: trends},
month = jul,
number = {7},
pages = {585--7},
pmid = {18587314},
title = {{The beginning of the end for microarrays?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18587314},
volume = {5},
year = {2008}
}
@article{Korbel2007,
abstract = {Structural variation of the genome involves kilobase- to megabase-sized deletions, duplications, insertions, inversions, and complex combinations of rearrangements. We introduce high-throughput and massive paired-end mapping (PEM), a large-scale genome-sequencing method to identify structural variants (SVs) approximately 3 kilobases (kb) or larger that combines the rescue and capture of paired ends of 3-kb fragments, massive 454 sequencing, and a computational approach to map DNA reads onto a reference genome. PEM was used to map SVs in an African and in a putatively European individual and identified shared and divergent SVs relative to the reference genome. Overall, we fine-mapped more than 1000 SVs and documented that the number of SVs among humans is much larger than initially hypothesized; many of the SVs potentially affect gene function. The breakpoint junction sequences of more than 200 SVs were determined with a novel pooling strategy and computational analysis. Our analysis provided insights into the mechanisms of SV formation in humans.},
author = {Korbel, Jan O and Urban, Alexander Eckehart and Affourtit, Jason P and Godwin, Brian and Grubert, Fabian and Simons, Jan Fredrik and Kim, Philip M and Palejev, Dean and Carriero, Nicholas J and Du, Lei and Taillon, Bruce E and Chen, Zhoutao and Tanzer, Andrea and Saunders, a C Eugenia and Chi, Jianxiang and Yang, Fengtang and Carter, Nigel P and Hurles, Matthew E and Weissman, Sherman M and Harkins, Timothy T and Gerstein, Mark B and Egholm, Michael and Snyder, Michael},
doi = {10.1126/science.1149504},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/18\_Paired\_End.pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Chromosome Inversion,Chromosome Mapping,Computational Biology,Female,Gene Fusion,Genetic Variation,Genome, Human,Humans,Mutagenesis, Insertional,Mutation,Oligonucleotide Array Sequence Analysis,Recombination, Genetic,Repetitive Sequences, Nucleic Acid,Retroelements,Sequence Analysis, DNA,Sequence Deletion},
month = oct,
number = {5849},
pages = {420--6},
pmid = {17901297},
title = {{Paired-end mapping reveals extensive structural variation in the human genome.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2674581\&tool=pmcentrez\&rendertype=abstract},
volume = {318},
year = {2007}
}
@article{Weber2011,
abstract = {Next-generation sequencing (NGS) technologies have enabled the application of broad-scale sequencing in microbial biodiversity and metagenome studies. Biodiversity is usually targeted by classifying 16S ribosomal RNA genes, while metagenomic approaches target metabolic genes. However, both approaches remain isolated, as long as the taxonomic and functional information cannot be interrelated. Techniques like self-organizing maps (SOMs) have been applied to cluster metagenomes into taxon-specific bins in order to link biodiversity with functions, but have not been applied to broad-scale NGS-based metagenomics yet. Here, we provide a novel implementation, demonstrate its potential and practicability, and provide a web-based service for public usage. Evaluation with published data sets mimicking varyingly complex habitats resulted into classification specificities and sensitivities of close to 100\% to above 90\% from phylum to genus level for assemblies exceeding 8 kb for low and medium complexity data. When applied to five real-world metagenomes of medium complexity from direct pyrosequencing of marine subsurface waters, classifications of assemblies above 2.5 kb were in good agreement with fluorescence in situ hybridizations, indicating that biodiversity was mostly retained within the metagenomes, and confirming high classification specificities. This was validated by two protein-based classifications (PBCs) methods. SOMs were able to retrieve the relevant taxa down to the genus level, while surpassing PBCs in resolution. In order to make the approach accessible to a broad audience, we implemented a feature-rich web-based SOM application named TaxSOM, which is freely available at http://www.megx.net/toolbox/taxsom. TaxSOM can classify reads or assemblies exceeding 2.5 kb with high accuracy and thus assists in linking biodiversity and functions in metagenome studies, which is a precondition to study microbial ecology in a holistic fashion.},
author = {Weber, Marc and Teeling, Hanno and Huang, Sixing and Waldmann, Jost and Kassabgy, Mariette and Fuchs, Bernhard M and Klindworth, Anna and Klockow, Christine and Wichels, Antje and Gerdts, Gunnar and Amann, Rudolf and Gl\"{o}ckner, Frank Oliver},
doi = {10.1038/ismej.2010.180},
file = {:home/binni/Downloads/ismej2010180a.pdf:pdf},
issn = {1751-7370},
journal = {The ISME journal},
keywords = {16S,16S: genetics,Algorithms,Biodiversity,Cluster Analysis,DNA,DNA: methods,Internet,Metagenomics,Metagenomics: methods,Phylogeny,RNA,Ribosomal,Seawater,Seawater: microbiology,Sensitivity and Specificity,Sequence Analysis,Software},
month = may,
number = {5},
pages = {918--28},
pmid = {21160538},
title = {{Practical application of self-organizing maps to interrelate biodiversity and functional data in NGS-based metagenomics.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3105762\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2011}
}
@article{Wu2011,
abstract = {Metagenomics is the study of microbial communities sampled directly from their natural environment, without prior culturing. Among the computational tools recently developed for metagenomic sequence analysis, binning tools attempt to classify the sequences in a metagenomic dataset into different bins (i.e., species), based on various DNA composition patterns (e.g., the tetramer frequencies) of various genomes. Composition-based binning methods, however, cannot be used to classify very short fragments, because of the substantial variation of DNA composition patterns within a single genome. We developed a novel approach (AbundanceBin) for metagenomics binning by utilizing the different abundances of species living in the same environment. AbundanceBin is an application of the Lander-Waterman model to metagenomics, which is based on the l-tuple content of the reads. AbundanceBin achieved accurate, unsupervised, clustering of metagenomic sequences into different bins, such that the reads classified in a bin belong to species of identical or very similar abundances in the sample. In addition, AbundanceBin gave accurate estimations of species abundances, as well as their genome sizes-two important parameters for characterizing a microbial community. We also show that AbundanceBin performed well when the sequence lengths are very short (e.g., 75 bp) or have sequencing errors. By combining AbundanceBin and a composition-based method (MetaCluster), we can achieve even higher binning accuracy. Supplementary Material is available at www.liebertonline.com/cmb .},
author = {Wu, Yu-Wei and Ye, Yuzhen},
doi = {10.1089/cmb.2010.0245},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Ye - 2011 - A novel abundance-based algorithm for binning metagenomic sequences using l-tuples(2).pdf:pdf},
issn = {1557-8666},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {Algorithms,DNA,DNA: genetics,Databases, Genetic,Genome, Bacterial,Metagenomics,Metagenomics: methods,Sequence Analysis, DNA},
month = mar,
number = {3},
pages = {523--34},
pmid = {21385052},
title = {{A novel abundance-based algorithm for binning metagenomic sequences using l-tuples.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3123841\&tool=pmcentrez\&rendertype=abstract},
volume = {18},
year = {2011}
}
@article{Mardis2007,
author = {Mardis, Elaine R},
doi = {10.1038/nmeth0807-613},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/20\_Solexa.pdf:pdf},
issn = {1548-7091},
journal = {Nature methods},
keywords = {Chromatin Immunoprecipitation,Chromatin Immunoprecipitation: methods,DNA,DNA: metabolism,Genome,Protein Binding,Transcription Factors,Transcription Factors: metabolism},
month = aug,
number = {8},
pages = {613--4},
pmid = {17664943},
title = {{ChIP-seq: welcome to the new frontier.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22753428},
volume = {4},
year = {2007}
}
@article{Wooley2010a,
abstract = {Metagenomics is a discipline that enables the genomic study of uncultured microorganisms. Faster, cheaper sequencing technologies and the ability to sequence uncultured microbes sampled directly from their habitats are expanding and transforming our view of the microbial world. Distilling meaningful information from the millions of new genomic sequences presents a serious challenge to bioinformaticians. In cultured microbes, the genomic data come from a single clone, making sequence assembly and annotation tractable. In metagenomics, the data come from heterogeneous microbial communities, sometimes containing more than 10,000 species, with the sequence data being noisy and partial. From sampling, to assembly, to gene calling and function prediction, bioinformatics faces new demands in interpreting voluminous, noisy, and often partial sequence data. Although metagenomics is a relative newcomer to science, the past few years have seen an explosion in computational methods applied to metagenomic-based research. It is therefore not within the scope of this article to provide an exhaustive review. Rather, we provide here a concise yet comprehensive introduction to the current computational requirements presented by metagenomics, and review the recent progress made. We also note whether there is software that implements any of the methods presented here, and briefly review its utility. Nevertheless, it would be useful if readers of this article would avail themselves of the comment section provided by this journal, and relate their own experiences. Finally, the last section of this article provides a few representative studies illustrating different facets of recent scientific discoveries made using metagenomics.},
author = {Wooley, John C and Godzik, Adam and Friedberg, Iddo},
doi = {10.1371/journal.pcbi.1000667},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wooley, Godzik, Friedberg - 2010 - A primer on metagenomics.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Computational Biology,DNA,Metagenomics,Sequence Analysis},
month = mar,
number = {2},
pages = {e1000667},
pmid = {20195499},
title = {{A primer on metagenomics.}},
url = {http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1000667\#s1},
volume = {6},
year = {2010}
}
@article{Dunbar2006,
abstract = {As we enter the post-genome sequencing era and begin to sift through the enormous amount of genetic information now available, the need for technologies that allow rapid, cost-effective, high-throughput detection of specific nucleic acid sequences becomes apparent. Multiplexing technologies, which allow for simultaneous detection of multiple nucleic acid sequences in a single reaction, can greatly reduce the time, cost and labor associated with single reaction detection technologies.},
author = {Dunbar, Sherry a},
doi = {10.1016/j.cccn.2005.06.023},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/2\_Luminex\_Review.pdf:pdf},
issn = {0009-8981},
journal = {Clinica chimica acta; international journal of clinical chemistry},
keywords = {Animals,DNA Mutational Analysis,DNA Mutational Analysis: instrumentation,DNA Mutational Analysis: methods,DNA Probes,Gene Expression Profiling,Genetic Predisposition to Disease,Genetic Testing,Genotype,Humans,Nucleic Acid Amplification Techniques,Nucleic Acid Amplification Techniques: instrumenta,Nucleic Acid Amplification Techniques: methods,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: instrumen,Oligonucleotide Array Sequence Analysis: methods,Polymorphism, Single Nucleotide,RNA,RNA: analysis,Sensitivity and Specificity},
month = jan,
number = {1-2},
pages = {71--82},
pmid = {16102740},
title = {{Applications of Luminex xMAP technology for rapid, high-throughput multiplexed nucleic acid detection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16102740},
volume = {363},
year = {2006}
}
@article{Fan2000,
abstract = {Large scale human genetic studies require technologies for generating millions of genotypes with relative ease but also at a reasonable cost and with high accuracy. We describe a highly parallel method for genotyping single nucleotide polymorphisms (SNPs), using generic high-density oligonucleotide arrays that contain thousands of preselected 20-mer oligonucleotide tags. First, marker-specific primers are used in PCR amplifications of genomic regions containing SNPs. Second, the amplification products are used as templates in single base extension (SBE) reactions using chimeric primers with 3' complementarity to the specific SNP loci and 5' complementarity to specific probes, or tags, synthesized on the array. The SBE primers, terminating one base before the polymorphic site, are extended in the presence of labeled dideoxy NTPs, using a different label for each of the two SNP alleles, and hybridized to the tag array. Third, genotypes are deduced from the fluorescence intensity ratio of the two colors. This approach takes advantage of multiplexed sample preparation, hybridization, and analysis at each stage. We illustrate and test this method by genotyping 44 individuals for 142 human SNPs identified previously in 62 candidate hypertension genes. Because the hybridization results are quantitative, this method can also be used for allele-frequency estimation in pooled DNA samples.},
author = {Fan, J B and Chen, X and Halushka, M K and Berno, a and Huang, X and Ryder, T and Lipshutz, R J and Lockhart, D J and Chakravarti, a},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/7\_Tag\_Arrays.pdf:pdf},
issn = {1088-9051},
journal = {Genome research},
keywords = {Blood Pressure,Blood Pressure: genetics,DNA,DNA: analysis,Gene Amplification,Genotype,Humans,Hypertension,Hypertension: genetics,Nucleic Acid Hybridization,Nucleic Acid Hybridization: methods,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Polymorphism, Single Nucleotide,Polymorphism, Single Nucleotide: genetics},
month = jun,
number = {6},
pages = {853--60},
pmid = {10854416},
title = {{Parallel genotyping of human SNPs using generic high-density oligonucleotide tag arrays.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=310915\&tool=pmcentrez\&rendertype=abstract},
volume = {10},
year = {2000}
}
@article{Whitesides2004,
abstract = {Insights into conducting research and the writing of scientific papers are given by Prof. Whitesides in this short essay. The manuscript and its guidelines has been circulated within the Whitesides' research group since 1989.},
archivePrefix = {arXiv},
arxivId = {1003.3921v1},
author = {Whitesides, G  M},
chapter = {19},
doi = {10.1002/adma.200400767},
eprint = {1003.3921v1},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Whitesides - 2004 - Whitesides' Group Writing a Paper.pdf:pdf},
institution = {Department of Genome Sciences, University of Washington, Seattle, Washington 98195-5065, USA. shendure@u.washington.edu},
isbn = {3825208028},
issn = {09359648},
journal = {Advanced Materials},
number = {15},
pages = {1375--1377},
publisher = {Deerfield Beach, FL: VCH Publishers,[1989]-},
series = {WISICT '04},
title = {{Whitesides' Group: Writing a Paper}},
url = {http://doi.wiley.com/10.1002/adma.200400767},
volume = {16},
year = {2004}
}
@article{Alon2009,
abstract = {Choosing good problems is essential for being a good scientist. But what is a good problem, and how do you choose one? The subject is not usually discussed explicitly within our profession. Scientists are expected to be smart enough to figure it out on their own and through the observation of their teachers. This lack of explicit discussion leaves a vacuum that can lead to approaches such as choosing problems that can give results that merit publication in valued journals, resulting in a job and tenure.},
author = {Alon, Uri},
chapter = {19},
editor = {Inc, Elsevier},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alon - 2009 - How to choose a good scientific problem.pdf:pdf},
institution = {Department Molecular Cell Biology, Weizmann Institute of Science, Rehovot 76100, Israel. urialon@weizmann.ac.il},
journal = {Molecular Cell},
number = {6},
pages = {726--728},
pmid = {19782018},
publisher = {Elsevier Inc.},
series = {WISICT '04},
title = {{How to choose a good scientific problem.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19782018},
volume = {35},
year = {2009}
}
@article{Shendure2008a,
abstract = {DNA sequence represents a single format onto which a broad range of biological phenomena can be projected for high-throughput data collection. Over the past three years, massively parallel DNA sequencing platforms have become widely available, reducing the cost of DNA sequencing by over two orders of magnitude, and democratizing the field by putting the sequencing capacity of a major genome center in the hands of individual investigators. These new technologies are rapidly evolving, and near-term challenges include the development of robust protocols for generating sequencing libraries, building effective new approaches to data-analysis, and often a rethinking of experimental design. Next-generation DNA sequencing has the potential to dramatically accelerate biological and biomedical research, by enabling the comprehensive analysis of genomes, transcriptomes and interactomes to become inexpensive, routine and widespread, rather than requiring significant production-scale efforts.},
author = {Shendure, Jay and Ji, Hanlee},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shendure, Ji - 2008 - Next-generation DNA sequencing.pdf:pdf},
institution = {Department of Genome Sciences, University of Washington, Seattle, Washington 98195-5065, USA. shendure@u.washington.edu},
journal = {Nature Biotechnology},
keywords = {chromosome mapping,chromosome mapping trends,dna,dna trends,forecasting,genomics,genomics trends,sequence alignment,sequence alignment trends,sequence analysis},
number = {10},
pages = {1135--1145},
pmid = {18846087},
publisher = {Nature Publishing Group},
title = {{Next-generation DNA sequencing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18846087},
volume = {26},
year = {2008}
}
@article{Kaller2007,
abstract = {Over the last few years, several initiatives have described efforts to combine previously invented techniques in molecular biology with parallel detection principles to sequence or genotype DNA signatures. The Infinium system from Illumina and the Affymetrix GeneChips are two systems suitable for whole-genome scoring of variable positions. However, directed candidate-gene approaches are more cost effective and several academic groups and the private sector provide techniques with moderate typing throughput combined with large sample capacity suiting these needs. Recently, whole-genome sequencing platforms based on the sequencing-by-synthesis principle were presented by 454 Life Sciences and Solexa, showing great potential as alternatives to conventional genotyping approaches. In addition to these sequencing initiatives, many efforts are pursuing novel ideas to facilitate fast and cost-effective whole genome sequencing, such as ligation-based sequencing. Reliable methods for routine re-sequencing of human genomes as a tool for personalized medicine, however, remain to be developed.},
author = {K\"{a}ller, Max and Lundeberg, Joakim and Ahmadian, Afshin},
doi = {10.1586/14737159.7.1.65},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/6\_Review\_Kaller.pdf:pdf},
issn = {1744-8352},
journal = {Expert review of molecular diagnostics},
keywords = {Base Sequence,Chromosome Mapping,DNA,DNA: genetics,Genetic Variation,Genome, Human,Humans,In Situ Hybridization,Molecular Biology,Molecular Biology: methods,Oligonucleotide Array Sequence Analysis,Polymorphism, Single Nucleotide},
month = jan,
number = {1},
pages = {65--76},
pmid = {17187485},
title = {{Arrayed identification of DNA signatures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17187485},
volume = {7},
year = {2007}
}
@article{Pettersson2006,
abstract = {Efforts to correlate genetic variations with phenotypic differences are intensifying due to the availability of high-density maps of single nucleotide polymorphisms (SNPs) and the development of high throughput scoring methods. These recent advances have led to an increased interest for improved multiplex preparations of genetic material to facilitate such whole genome analyses. Here we propose a strategy for the parallel amplification of polymorphic loci based on a reduced set of nucleotides. The technique denoted Tri-nucleotide Threading (TnT), allows SNPs to be amplified via controlled linear amplification followed by complete removal of the target material and subsequent amplification with a pair of universal primers. A dedicated software tool was developed for this purpose and variable positions in genes associated with different forms of cancer were analyzed using sub-nanogram amounts of starting material. The amplified fragments were then successfully scored using a microarray-based PrASE technique. The results of this study, in which 75 SNPs were analyzed, show that the TnT technique circumvents potential problems associated with multiplex amplification of SNPs from minute amounts of material. The technique is specific, sensitive and can be readily adapted to equipment and genotyping techniques used in other research laboratories without requiring changes to the preferred typing method.},
author = {Pettersson, Erik and Lindskog, Mats and Lundeberg, Joakim and Ahmadian, Afshin},
doi = {10.1093/nar/gkl103},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/10\_TnT.pdf:pdf},
issn = {1362-4962},
journal = {Nucleic acids research},
keywords = {Cytidine Triphosphate,Cytidine Triphosphate: chemistry,Genome, Human,Genomics,Genomics: methods,Genotype,Guanosine Triphosphate,Guanosine Triphosphate: chemistry,Humans,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Polymerase Chain Reaction,Polymerase Chain Reaction: methods,Polymorphism, Single Nucleotide,Software,Thymine Nucleotides,Thymine Nucleotides: chemistry},
month = jan,
number = {6},
pages = {e49},
pmid = {16582098},
title = {{Tri-nucleotide threading for parallel amplification of minute amounts of genomic DNA.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1421508\&tool=pmcentrez\&rendertype=abstract},
volume = {34},
year = {2006}
}
@article{Mardis2008a,
abstract = {Recent scientific discoveries that resulted from the application of next-generation DNA sequencing technologies highlight the striking impact of these massively parallel platforms on genetics. These new methods have expanded previously focused readouts from a variety of DNA preparation protocols to a genome-wide scale and have fine-tuned their resolution to single base precision. The sequencing of RNA also has transitioned and now includes full-length cDNA analyses, serial analysis of gene expression (SAGE)-based methods, and noncoding RNA discovery. Next-generation sequencing has also enabled novel applications such as the sequencing of ancient DNA samples, and has substantially widened the scope of metagenomic analysis of environmentally derived samples. Taken together, an astounding potential exists for these technologies to bring enormous change in genetic and biological research and to enhance our fundamental biological knowledge.},
author = {Mardis, Elaine R},
doi = {10.1146/annurev.genom.9.081307.164359},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/14\_1Review\_Mardis.pdf:pdf},
issn = {1527-8204},
journal = {Annual review of genomics and human genetics},
keywords = {Chromatin Immunoprecipitation,Chromatin Immunoprecipitation: methods,Fossils,Gene Expression Profiling,Gene Expression Profiling: methods,Genome, Human,Genomics,Genomics: methods,Humans,RNA, Untranslated,RNA, Untranslated: genetics,Sequence Analysis, DNA,Sequence Analysis, DNA: instrumentation,Sequence Analysis, DNA: methods,Sequence Analysis, DNA: trends},
month = jan,
number = {June},
pages = {387--402},
pmid = {18576944},
title = {{Next-generation DNA sequencing methods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18576944},
volume = {9},
year = {2008}
}
@article{Flusberg2010,
abstract = {We describe the direct detection of DNA methylation, without bisulfite conversion, through single-molecule, real-time (SMRT) sequencing. In SMRT sequencing, DNA polymerases catalyze the incorporation of fluorescently labeled nucleotides into complementary nucleic acid strands. The arrival times and durations of the resulting fluorescence pulses yield information about polymerase kinetics and allow direct detection of modified nucleotides in the DNA template, including N6-methyladenine, 5-methylcytosine and 5-hydroxymethylcytosine. Measurement of polymerase kinetics is an intrinsic part of SMRT sequencing and does not adversely affect determination of primary DNA sequence. The various modifications affect polymerase kinetics differently, allowing discrimination between them. We used these kinetic signatures to identify adenine methylation in genomic samples and found that, in combination with circular consensus sequencing, they can enable single-molecule identification of epigenetic modifications with base-pair resolution. This method is amenable to long read lengths and will likely enable mapping of methylation patterns in even highly repetitive genomic regions.},
author = {Flusberg, Benjamin a and Webster, Dale R and Lee, Jessica H and Travers, Kevin J and Olivares, Eric C and Clark, Tyson a and Korlach, Jonas and Turner, Stephen W},
doi = {10.1038/nmeth.1459},
file = {:home/binni/Dropbox/KTH/Haust2012/BB2470/Articles/25\_PacBio\_Methylation.pdf:pdf},
issn = {1548-7105},
journal = {Nature methods},
keywords = {DNA Methylation,DNA-Directed DNA Polymerase,DNA-Directed DNA Polymerase: metabolism,Escherichia coli,Escherichia coli: genetics,Kinetics,Principal Component Analysis,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = jun,
number = {6},
pages = {461--5},
pmid = {20453866},
publisher = {Nature Publishing Group},
title = {{Direct detection of DNA methylation during single-molecule, real-time sequencing.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2879396\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2010}
}
@article{Wooley2010,
abstract = {Metagenomics is a discipline that enables the genomic study of uncultured microorganisms. Faster, cheaper sequencing technologies and the ability to sequence uncultured microbes sampled directly from their habitats are expanding and transforming our view of the microbial world. Distilling meaningful information from the millions of new genomic sequences presents a serious challenge to bioinformaticians. In cultured microbes, the genomic data come from a single clone, making sequence assembly and annotation tractable. In metagenomics, the data come from heterogeneous microbial communities, sometimes containing more than 10,000 species, with the sequence data being noisy and partial. From sampling, to assembly, to gene calling and function prediction, bioinformatics faces new demands in interpreting voluminous, noisy, and often partial sequence data. Although metagenomics is a relative newcomer to science, the past few years have seen an explosion in computational methods applied to metagenomic-based research. It is therefore not within the scope of this article to provide an exhaustive review. Rather, we provide here a concise yet comprehensive introduction to the current computational requirements presented by metagenomics, and review the recent progress made. We also note whether there is software that implements any of the methods presented here, and briefly review its utility. Nevertheless, it would be useful if readers of this article would avail themselves of the comment section provided by this journal, and relate their own experiences. Finally, the last section of this article provides a few representative studies illustrating different facets of recent scientific discoveries made using metagenomics.},
author = {Wooley, John C and Godzik, Adam and Friedberg, Iddo},
doi = {10.1371/journal.pcbi.1000667},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wooley, Godzik, Friedberg - 2010 - A primer on metagenomics.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Computational Biology,Metagenomics,Sequence Analysis, DNA},
month = mar,
number = {2},
pages = {e1000667},
pmid = {20195499},
title = {{A primer on metagenomics.}},
url = {http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1000667\#s1},
volume = {6},
year = {2010}
}
@article{Strous2012,
abstract = {So far, microbial physiology has dedicated itself mainly to pure cultures. In nature, cross feeding and competition are important aspects of microbial physiology and these can only be addressed by studying complete communities such as enrichment cultures. Metagenomic sequencing is a powerful tool to characterize such mixed cultures. In the analysis of metagenomic data, well established algorithms exist for the assembly of short reads into contigs and for the annotation of predicted genes. However, the binning of the assembled contigs or unassembled reads is still a major bottleneck and required to understand how the overall metabolism is partitioned over different community members. Binning consists of the clustering of contigs or reads that apparently originate from the same source population. In the present study eight metagenomic samples from the same habitat, a laboratory enrichment culture, were sequenced. Each sample contained 13-23 Mb of assembled contigs and up to eight abundant populations. Binning was attempted with existing methods but they were found to produce poor results, were slow, dependent on non-standard platforms or produced errors. A new binning procedure was developed based on multivariate statistics of tetranucleotide frequencies combined with the use of interpolated Markov models. Its performance was evaluated by comparison of the results between samples with BLAST and in comparison to existing algorithms for four publicly available metagenomes and one previously published artificial metagenome. The accuracy of the new approach was comparable or higher than existing methods. Further, it was up to a 100 times faster. It was implemented in Java Swing as a complete open source graphical binning application available for download and further development (http://sourceforge.net/projects/metawatt).},
author = {Strous, Marc and Kraft, Beate and Bisdorf, Regina and Tegetmeyer, Halina E.},
doi = {10.3389/fmicb.2012.00410},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strous et al. - 2012 - The Binning of Metagenomic Contigs for Microbial Physiology of Mixed Cultures(2).pdf:pdf},
issn = {1664-302X},
journal = {Frontiers in Microbiology},
month = jan,
pages = {410},
pmid = {23227024},
title = {{The Binning of Metagenomic Contigs for Microbial Physiology of Mixed Cultures}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3514610\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2012}
}
@article{Leung2011a,
abstract = {With the rapid development of next-generation sequencing techniques, metagenomics, also known as environmental genomics, has emerged as an exciting research area that enables us to analyze the microbial environment in which we live. An important step for metagenomic data analysis is the identification and taxonomic characterization of DNA fragments (reads or contigs) resulting from sequencing a sample of mixed species. This step is referred to as 'binning'. Binning algorithms that are based on sequence similarity and sequence composition markers rely heavily on the reference genomes of known microorganisms or phylogenetic markers. Due to the limited availability of reference genomes and the bias and low availability of markers, these algorithms may not be applicable in all cases. Unsupervised binning algorithms which can handle fragments from unknown species provide an alternative approach. However, existing unsupervised binning algorithms only work on datasets either with balanced species abundance ratios or rather different abundance ratios, but not both.},
author = {Leung, Henry C M and Yiu, S M and Yang, Bin and Peng, Yu and Wang, Yi and Liu, Zhihua and Chen, Jingchi and Qin, Junjie and Li, Ruiqiang and Chin, Francis Y L},
doi = {10.1093/bioinformatics/btr186},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leung et al. - 2011 - A robust and accurate binning algorithm for metagenomic sequences with arbitrary species abundance ratio.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Cluster Analysis,Metagenomics,Metagenomics: methods,Sequence Analysis, DNA},
month = jun,
number = {11},
pages = {1489--95},
pmid = {21493653},
title = {{A robust and accurate binning algorithm for metagenomic sequences with arbitrary species abundance ratio.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21493653},
volume = {27},
year = {2011}
}
@article{Muto1987,
abstract = {The genomic guanine and cytosine (G + C) content of eubacteria is related to their phylogeny. The G + C content of various parts of the genome (protein genes, stable RNA genes, and spacers) reveals a positive linear correlation with the G + C content of their genomic DNA. However, the plotted correlation slopes differ among various parts of the genome or among the first, second, and third positions of the codons depending on their functional importance. Facts suggest that biased mutation pressure, called A X T/G X C pressure, has affected whole DNA during evolution so as to determine the genomic G + C content in a given bacterium. The role of A X T/G X C pressure in diversification of bacterial DNA sequences and codon usage patterns is discussed in the perspective of the neutral theory of molecular evolution.},
author = {Muto, a and Osawa, S},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Muto, Osawa - 1987 - The guanine and cytosine content of genomic DNA and bacterial evolution.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Biological Evolution,Codon,Cytosine,DNA, Bacterial,DNA, Bacterial: genetics,Genes, Bacterial,Guanine,Models, Genetic},
month = jan,
number = {1},
pages = {166--9},
pmid = {3467347},
title = {{The guanine and cytosine content of genomic DNA and bacterial evolution.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=304163\&tool=pmcentrez\&rendertype=abstract},
volume = {84},
year = {1987}
}
@article{Pride2003,
abstract = {We compared nucleotide usage pattern conservation for related prokaryotes by examining the representation of DNA tetranucleotide combinations in 27 representative microbial genomes. For each of the organisms studied, tetranucleotide usage departures from expectations (TUD) were shared between related organisms using both Markov chain analysis and a zero-order Markov method. Individual strains, multiple chromosomes, plasmids, and bacteriophages share TUDs within a species. TUDs varied between coding and noncoding DNA. Grouping prokaryotes based on TUD profiles resulted in relationships with important differences from those based on 16S rRNA phylogenies, which may reflect unequal rates of evolution of nucleotide usage patterns following divergence of particular organisms from a common ancestor. By both symmetrical tree distance and likelihood analysis, phylogenetic trees based on TUD profiles demonstrate a level of congruence with 16S rRNA trees similar to that of both RpoA and RecA trees. Congruence of these trees indicates that there exists phylogenetic signal in TUD patterns, most prominent in coding region DNA. Because relationships demonstrated in TUD-based analyses utilize whole genomes, they should be considered complementary to phylogenies based on single genetic elements, such as 16S rRNA.},
author = {Pride, David T and Meinersmann, Richard J and Wassenaar, Trudy M and Blaser, Martin J},
doi = {10.1101/gr.335003},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pride et al. - 2003 - Evolutionary implications of microbial genome tetranucleotide frequency biases.pdf:pdf},
issn = {1088-9051},
journal = {Genome research},
keywords = {Chromosome Mapping,Chromosome Mapping: methods,Chromosome Mapping: statistics \& numerical data,Chromosomes, Archaeal,Chromosomes, Archaeal: genetics,Chromosomes, Bacterial,Chromosomes, Bacterial: genetics,Cluster Analysis,DNA, Archaeal,DNA, Archaeal: genetics,DNA, Bacterial,DNA, Bacterial: genetics,Gene Transfer, Horizontal,Gene Transfer, Horizontal: genetics,Genome, Archaeal,Genome, Bacterial,Gram-Negative Bacteria,Gram-Negative Bacteria: genetics,Gram-Positive Bacteria,Gram-Positive Bacteria: genetics,Microsatellite Repeats,Microsatellite Repeats: genetics,Phylogeny,Plasmids,Plasmids: genetics,RNA, Archaeal,RNA, Archaeal: genetics,RNA, Bacterial,RNA, Bacterial: genetics,RNA, Ribosomal, 16S,RNA, Ribosomal, 16S: genetics,Spirochaeta,Spirochaeta: genetics},
month = feb,
number = {2},
pages = {145--58},
pmid = {12566393},
title = {{Evolutionary implications of microbial genome tetranucleotide frequency biases.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=420360\&tool=pmcentrez\&rendertype=abstract},
volume = {13},
year = {2003}
}
@article{Wang2012c,
abstract = {Next-generation sequencing (NGS) technologies allow the sequencing of microbial communities directly from the environment without prior culturing. The output of environmental DNA sequencing consists of many reads from genomes of different unknown species, making the clustering together reads from the same (or similar) species (also known as binning) a crucial step. The difficulties of the binning problem are due to the following four factors: (1) the lack of reference genomes; (2) uneven abundance ratio of species; (3) short NGS reads; and (4) a large number of species (can be more than a hundred). None of the existing binning tools can handle all four factors. No tools, including both AbundanceBin and MetaCluster 3.0, have demonstrated reasonable performance on a sample with more than 20 species. In this article, we introduce MetaCluster 4.0, an unsupervised binning algorithm that can accurately (with about 80\% precision and sensitivity in all cases and at least 90\% in some cases) and efficiently bin short reads with varying abundance ratios and is able to handle datasets with 100 species. The novelty of MetaCluster 4.0 stems from solving a few important problems: how to divide reads into groups by a probabilistic approach, how to estimate the 4-mer distribution of each group, how to estimate the number of species, and how to modify MetaCluster 3.0 to handle a large number of species. We show that Meta Cluster 4.0 is effective for both simulated and real datasets. Supplementary Material is available at www.liebertonline.com/cmb.},
author = {Wang, Yi and Leung, Henry C M and Yiu, S M and Chin, Francis Y L},
doi = {10.1089/cmb.2011.0276},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2012 - MetaCluster 4.0 a novel binning algorithm for NGS reads and huge number of species.pdf:pdf},
issn = {1557-8666},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {Algorithms,Bacteria,Bacteria: genetics,Base Sequence,Cluster Analysis,Data Interpretation, Statistical,Genome, Bacterial,High-Throughput Nucleotide Sequencing,Models, Statistical,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Software},
month = feb,
number = {2},
pages = {241--9},
pmid = {22300323},
title = {{MetaCluster 4.0: a novel binning algorithm for NGS reads and huge number of species.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22300323},
volume = {19},
year = {2012}
}
@article{Mengersen2013,
abstract = {Approximate Bayesian computation has become an essential tool for the analysis of complex stochastic models when the likelihood function is numerically unavailable. However, the well-established statistical method of empirical likelihood provides another route to such settings that bypasses simulations from the model and the choices of the approximate Bayesian computation parameters (summary statistics, distance, tolerance), while being convergent in the number of observations. Furthermore, bypassing model simulations may lead to significant time savings in complex models, for instance those found in population genetics. The Bayesian computation with empirical likelihood algorithm we develop in this paper also provides an evaluation of its own performance through an associated effective sample size. The method is illustrated using several examples, including estimation of standard distributions, time series, and population genetics models.},
author = {Mengersen, Kerrie L and Pudlo, Pierre and Robert, Christian P},
file = {:home/binni/Downloads/PNAS-2013-Mengersen-1321-6.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = jan,
number = {4},
pages = {1321--1326},
title = {{Bayesian computation via empirical likelihood.}},
url = {http://www.pnas.org/cgi/content/long/110/4/1321},
volume = {110},
year = {2013}
}
@article{Teeling2004a,
abstract = {A basic problem of the metagenomic approach in microbial ecology is the assignment of genomic fragments to a certain species or taxonomic group, when suitable marker genes are absent. Currently, the (G + C)-content together with phylogenetic information and codon adaptation for functional genes is mostly used to assess the relationship of different fragments. These methods, however, can produce ambiguous results. In order to evaluate sequence-based methods for fragment identification, we extensively compared (G + C)-contents and tetranucleotide usage patterns of 9054 fosmid-sized genomic fragments generated in silico from 118 completely sequenced bacterial genomes (40 982 931 fragment pairs were compared in total). The results of this systematic study show that the discriminatory power of correlations of tetranucleotide-derived z-scores is by far superior to that of differences in (G + C)-content and provides reasonable assignment probabilities when applied to metagenome libraries of small diversity. Using six fully sequenced fosmid inserts from a metagenomic analysis of microbial consortia mediating the anaerobic oxidation of methane (AOM), we demonstrate that discrimination based on tetranucleotide-derived z-score correlations was consistent with corresponding data from 16S ribosomal RNA sequence analysis and allowed us to discriminate between fosmid inserts that were indistinguishable with respect to their (G + C)-contents.},
author = {Teeling, Hanno and Meyerdierks, Anke and Bauer, Margarete and Amann, Rudolf and Gl\"{o}ckner, Frank Oliver},
doi = {10.1111/j.1462-2920.2004.00624.x},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Teeling et al. - 2004 - Application of tetranucleotide frequencies for the assignment of genomic fragments.pdf:pdf},
issn = {1462-2912},
journal = {Environmental microbiology},
keywords = {Bacteria,Bacteria: genetics,Base Composition,Databases, Genetic,Genome, Bacterial,Genomics,Genomics: methods,Likelihood Functions,Nucleotides,Nucleotides: genetics,Species Specificity},
month = sep,
number = {9},
pages = {938--47},
pmid = {15305919},
title = {{Application of tetranucleotide frequencies for the assignment of genomic fragments.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15305919},
volume = {6},
year = {2004}
}
@article{Karlin1998,
abstract = {Early biochemical experiments measuring nearest neighbor frequencies established that the set of dinucleotide relative abundance values (dinucleotide biases) is a remarkably stable property of the DNA of an organism. Analyses of currently available genomic sequence data have extended these earlier results, showing that the dinucleotide biases evaluated for successive 50 kb segments of a genome are significantly more similar to each other than to those of sequences from more distant organisms. From this perspective, the set of dinucleotide biases constitutes a 'genomic signature' that can discriminate sequences from different organisms. The dinucleotide biases appear to reflect species-specific properties of DNA stacking energies, modification, replication, and repair mechanisms. The genomic signature is useful for detecting pathogenicity islands in bacterial genomes.},
author = {Karlin, S},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karlin - 1998 - Global dinucleotide signatures and analysis of genomic heterogeneity.pdf:pdf},
issn = {1369-5274},
journal = {Current opinion in microbiology},
keywords = {Bacteria,Bacteria: classification,Base Composition,Genome, Archaeal,Genome, Bacterial,Oligodeoxyribonucleotides,Phylogeny,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = oct,
number = {5},
pages = {598--610},
pmid = {10066522},
title = {{Global dinucleotide signatures and analysis of genomic heterogeneity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10066522},
volume = {1},
year = {1998}
}
@article{Hugenholtz2008a,
author = {Hugenholtz, Philip and Tyson, Gene W},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hugenholtz, Tyson - 2008 - Q \& A Metagenomics(2).pdf:pdf},
number = {August 2006},
pages = {2006--2008},
title = {{Q \& A Metagenomics}},
volume = {455},
year = {2008}
}
@article{Bustamam2011,
abstract = {Markov clustering (MCL) is becoming a key algorithm within bioinformatics for determining clusters in networks. However, with increasing vast amounts of data on biological networks, performance and scalability issues are becoming a critical limiting factor in applications. Meanwhile, GPU computing, which uses CUDA tool for implementing a massively parallel computing environment in the GPU card, is becoming a very powerful, efficient and low cost option to achieve substantial performance gains over CPU approaches. The use of on-chip memory on the GPU is efficiently lowering the latency time thus circumventing a major issue in other parallel computing environments, such as MPI. We introduce a very fast Markov clustering algorithm using CUDA (CUDA-MCL) to perform parallel sparse matrix-matrix computations and parallel sparse Markov matrix normalizations, which are at the heart of MCL. We utilized ELLPACK-R sparse format to allow the effective and fine-grain massively parallel processing to cope with the sparse nature of interaction networks datasets in bioinformatics applications. As the results show, CUDA-MCL is significantly faster than the original MCL running on CPU. Thus, large-scale parallel computation on off-the-shelf desktop-machines, that were previously only possible on supercomputing architectures, can significantly change the way bioinformaticians and biologists deal with their data.},
author = {Bustamam, Alhadi and Burrage, Kevin and Hamilton, Nicholas A},
doi = {10.1109/TCBB.2011.68},
file = {:home/binni/Downloads/06171972.pdf:pdf},
issn = {15579964},
journal = {IEEEACM transactions on computational biology and bioinformatics IEEE ACM},
number = {3},
pages = {679--692},
pmid = {21483031},
title = {{Fast Parallel Markov Clustering in Bioinformatics using Massively Parallel Computing on GPU with CUDA and ELLPACK-R Sparse Format.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21483031},
volume = {9},
year = {2011}
}
@article{Weber2011a,
abstract = {Next-generation sequencing (NGS) technologies have enabled the application of broad-scale sequencing in microbial biodiversity and metagenome studies. Biodiversity is usually targeted by classifying 16S ribosomal RNA genes, while metagenomic approaches target metabolic genes. However, both approaches remain isolated, as long as the taxonomic and functional information cannot be interrelated. Techniques like self-organizing maps (SOMs) have been applied to cluster metagenomes into taxon-specific bins in order to link biodiversity with functions, but have not been applied to broad-scale NGS-based metagenomics yet. Here, we provide a novel implementation, demonstrate its potential and practicability, and provide a web-based service for public usage. Evaluation with published data sets mimicking varyingly complex habitats resulted into classification specificities and sensitivities of close to 100\% to above 90\% from phylum to genus level for assemblies exceeding 8 kb for low and medium complexity data. When applied to five real-world metagenomes of medium complexity from direct pyrosequencing of marine subsurface waters, classifications of assemblies above 2.5 kb were in good agreement with fluorescence in situ hybridizations, indicating that biodiversity was mostly retained within the metagenomes, and confirming high classification specificities. This was validated by two protein-based classifications (PBCs) methods. SOMs were able to retrieve the relevant taxa down to the genus level, while surpassing PBCs in resolution. In order to make the approach accessible to a broad audience, we implemented a feature-rich web-based SOM application named TaxSOM, which is freely available at http://www.megx.net/toolbox/taxsom. TaxSOM can classify reads or assemblies exceeding 2.5 kb with high accuracy and thus assists in linking biodiversity and functions in metagenome studies, which is a precondition to study microbial ecology in a holistic fashion.},
author = {Weber, Marc and Teeling, Hanno and Huang, Sixing and Waldmann, Jost and Kassabgy, Mariette and Fuchs, Bernhard M and Klindworth, Anna and Klockow, Christine and Wichels, Antje and Gerdts, Gunnar and Amann, Rudolf and Gl\"{o}ckner, Frank Oliver},
doi = {10.1038/ismej.2010.180},
file = {:home/binni/Downloads/ismej2010180a.pdf:pdf},
issn = {1751-7370},
journal = {The ISME journal},
keywords = {16S,16S: genetics,Algorithms,Biodiversity,Cluster Analysis,DNA,DNA: methods,Internet,Metagenomics,Metagenomics: methods,Phylogeny,RNA,Ribosomal,Seawater,Seawater: microbiology,Sensitivity and Specificity,Sequence Analysis,Software},
month = may,
number = {5},
pages = {918--28},
pmid = {21160538},
title = {{Practical application of self-organizing maps to interrelate biodiversity and functional data in NGS-based metagenomics.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3105762\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2011}
}
@article{Wu2011a,
abstract = {Metagenomics is the study of microbial communities sampled directly from their natural environment, without prior culturing. Among the computational tools recently developed for metagenomic sequence analysis, binning tools attempt to classify the sequences in a metagenomic dataset into different bins (i.e., species), based on various DNA composition patterns (e.g., the tetramer frequencies) of various genomes. Composition-based binning methods, however, cannot be used to classify very short fragments, because of the substantial variation of DNA composition patterns within a single genome. We developed a novel approach (AbundanceBin) for metagenomics binning by utilizing the different abundances of species living in the same environment. AbundanceBin is an application of the Lander-Waterman model to metagenomics, which is based on the l-tuple content of the reads. AbundanceBin achieved accurate, unsupervised, clustering of metagenomic sequences into different bins, such that the reads classified in a bin belong to species of identical or very similar abundances in the sample. In addition, AbundanceBin gave accurate estimations of species abundances, as well as their genome sizes-two important parameters for characterizing a microbial community. We also show that AbundanceBin performed well when the sequence lengths are very short (e.g., 75 bp) or have sequencing errors. By combining AbundanceBin and a composition-based method (MetaCluster), we can achieve even higher binning accuracy. Supplementary Material is available at www.liebertonline.com/cmb .},
author = {Wu, Yu-Wei and Ye, Yuzhen},
doi = {10.1089/cmb.2010.0245},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Ye - 2011 - A novel abundance-based algorithm for binning metagenomic sequences using l-tuples(2).pdf:pdf},
issn = {1557-8666},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {Algorithms,DNA,DNA: genetics,Databases, Genetic,Genome, Bacterial,Metagenomics,Metagenomics: methods,Sequence Analysis, DNA},
month = mar,
number = {3},
pages = {523--34},
pmid = {21385052},
title = {{A novel abundance-based algorithm for binning metagenomic sequences using l-tuples.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3123841\&tool=pmcentrez\&rendertype=abstract},
volume = {18},
year = {2011}
}
@article{Hess2011a,
abstract = {The paucity of enzymes that efficiently deconstruct plant polysaccharides represents a major bottleneck for industrial-scale conversion of cellulosic biomass into biofuels. Cow rumen microbes specialize in degradation of cellulosic plant material, but most members of this complex community resist cultivation. To characterize biomass-degrading genes and genomes, we sequenced and analyzed 268 gigabases of metagenomic DNA from microbes adherent to plant fiber incubated in cow rumen. From these data, we identified 27,755 putative carbohydrate-active genes and expressed 90 candidate proteins, of which 57\% were enzymatically active against cellulosic substrates. We also assembled 15 uncultured microbial genomes, which were validated by complementary methods including single-cell genome sequencing. These data sets provide a substantially expanded catalog of genes and genomes participating in the deconstruction of cellulosic biomass.},
annote = {Methods.},
author = {Hess, Matthias and Sczyrba, Alexander and Egan, Rob and Kim, Tae-Wan and Chokhawala, Harshal and Schroth, Gary and Luo, Shujun and Clark, Douglas S and Chen, Feng and Zhang, Tao and Mackie, Roderick I and Pennacchio, Len a and Tringe, Susannah G and Visel, Axel and Woyke, Tanja and Wang, Zhong and Rubin, Edward M},
doi = {10.1126/science.1200387},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hess et al. - 2011 - Metagenomic discovery of biomass-degrading genes and genomes from cow rumen(2).pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Amino Acid Sequence,Animals,Bacteria,Bacteria: enzymology,Bacteria: genetics,Bacteria: isolation \& purification,Bacteria: metabolism,Bacterial Proteins,Bacterial Proteins: chemistry,Bacterial Proteins: genetics,Bacterial Proteins: metabolism,Biomass,Carbohydrate Metabolism,Cattle,Cattle: microbiology,Cellulase,Cellulase: genetics,Cellulase: metabolism,Cellulases,Cellulases: chemistry,Cellulases: genetics,Cellulases: metabolism,Cellulose,Cellulose 1,4-beta-Cellobiosidase,Cellulose 1,4-beta-Cellobiosidase: genetics,Cellulose 1,4-beta-Cellobiosidase: metabolism,Cellulose: metabolism,Genes, Bacterial,Genome, Bacterial,Metagenome,Metagenomics,Metagenomics: methods,Molecular Sequence Annotation,Molecular Sequence Data,Poaceae,Poaceae: microbiology,Rumen,Rumen: metabolism,Rumen: microbiology,Sequence Analysis, DNA},
month = jan,
number = {6016},
pages = {463--7},
pmid = {21273488},
title = {{Metagenomic discovery of biomass-degrading genes and genomes from cow rumen.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21273488},
volume = {331},
year = {2011}
}
@article{Wang2012b,
abstract = {Metagenomic binning remains an important topic in metagenomic analysis. Existing unsupervised binning methods for next-generation sequencing (NGS) reads do not perform well on (i) samples with low-abundance species or (ii) samples (even with high abundance) when there are many extremely low-abundance species. These two problems are common for real metagenomic datasets. Binning methods that can solve these problems are desirable.},
author = {Wang, Yi and Leung, Henry C M and Yiu, S M and Chin, Francis Y L},
doi = {10.1093/bioinformatics/bts397},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2012 - MetaCluster 5.0 a two-round binning approach for metagenomic data for low-abundance species in a noisy sample(2).pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
month = sep,
number = {18},
pages = {i356--i362},
pmid = {22962452},
title = {{MetaCluster 5.0: a two-round binning approach for metagenomic data for low-abundance species in a noisy sample.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3436824\&tool=pmcentrez\&rendertype=abstract},
volume = {28},
year = {2012}
}
@article{Kelley2010a,
abstract = {Sequencing of environmental DNA (often called metagenomics) has shown tremendous potential to uncover the vast number of unknown microbes that cannot be cultured and sequenced by traditional methods. Because the output from metagenomic sequencing is a large set of reads of unknown origin, clustering reads together that were sequenced from the same species is a crucial analysis step. Many effective approaches to this task rely on sequenced genomes in public databases, but these genomes are a highly biased sample that is not necessarily representative of environments interesting to many metagenomics projects.},
author = {Kelley, David R and Salzberg, Steven L},
doi = {10.1186/1471-2105-11-544},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelley, Salzberg - 2010 - Clustering metagenomic sequences with interpolated Markov models(3).pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Cluster Analysis,Databases, Factual,Markov Chains,Metagenomics,Metagenomics: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = jan,
number = {1},
pages = {544},
pmid = {21044341},
publisher = {BioMed Central Ltd},
title = {{Clustering metagenomic sequences with interpolated Markov models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3098094\&tool=pmcentrez\&rendertype=abstract},
volume = {11},
year = {2010}
}
@article{Dick2009a,
abstract = {Analyses of DNA sequences from cultivated microorganisms have revealed genome-wide, taxa-specific nucleotide compositional characteristics, referred to as genome signatures. These signatures have far-reaching implications for understanding genome evolution and potential application in classification of metagenomic sequence fragments. However, little is known regarding the distribution of genome signatures in natural microbial communities or the extent to which environmental factors shape them.},
author = {Dick, Gregory J and Andersson, Anders F and Baker, Brett J and Simmons, Sheri L and Thomas, Brian C and Yelton, a Pepper and Banfield, Jillian F},
doi = {10.1186/gb-2009-10-8-r85},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dick et al. - 2009 - Community-wide analysis of microbial genome sequence signatures(4).pdf:pdf},
issn = {1465-6914},
journal = {Genome biology},
keywords = {Bacteria,Bacteria: genetics,Bacteria: metabolism,Genomics,Iron,Mining,Soil Microbiology},
month = jan,
number = {8},
pages = {R85},
pmid = {19698104},
title = {{Community-wide analysis of microbial genome sequence signatures.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2745766\&tool=pmcentrez\&rendertype=abstract},
volume = {10},
year = {2009}
}
@misc{Zhang2011,
abstract = {Clustering is one of the most popular methods for data analysis, which is prevalent in many disciplines such as image segmentation, bioinformatics, pattern recognition and statistics etc. The most popular and simplest clustering algorithm is K-means because of its easy implementation, simplicity, efficiency and empirical success. However, the real-world applications produce huge volumes of data, thus, how to efficiently handle of these data in an important mining task has been a challenging and significant issue. In addition, MPI (Message Passing Interface) as a programming model of message passing presents high performances, scalability and portability. Motivated by this, a parallel K-means clustering algorithm with MPI, called MKmeans, is proposed in this paper. The algorithm enables applying the clustering algorithm effectively in the parallel environment. Experimental study demonstrates that MKmeans is relatively stable and portable, and it performs with low overhead of time on large volumes of data sets.},
author = {Zhang, Jing and Wu, Gongqing and Hu, Xuegang and Li, Shiying and Hao, Shuilong},
booktitle = {2011 Fourth International Symposium on Parallel Architectures Algorithms and Programming},
doi = {10.1109/PAAP.2011.17},
file = {:home/binni/Downloads/art\%3A10.1007\%2Fs11227-006-0002-7.pdf:pdf},
isbn = {9781457718083},
keywords = {clustering,k means algorithm,mpi,parallel computing},
number = {1},
pages = {60--64},
publisher = {IEEE},
title = {{A Parallel K-Means Clustering Algorithm with MPI}},
url = {http://www.springerlink.com/index/10.1007/s11227-006-0002-7},
volume = {39},
year = {2011}
}
@article{Mitra2010,
abstract = {Second-generation sequencing technologies are fueling a vast increase in the number and scope of metagenome projects. There is a great need for the development of new methods for visualizing the relationships between multiple metagenomic data sets. To address this, a novel approach is presented that combines the use of taxonomic analysis, ecological indices and non-hierarchical clustering to provide a network representation of the relationships between different metagenome data sets. The approach is illustrated using several published data sets of different types, including metagenomes, metatranscriptomes and 16S ribosomal profiles. Application of the approach to the same data summarized at different taxonomical levels gives rise to remarkably similar networks, indicating that the analysis is very robust. Importantly, the networks provide the both visual definition and metric quantification for the non-rooted relationship between samples, combining the desirable characteristics of other tools into one.},
author = {Mitra, Suparna and Gilbert, Jack a and Field, Dawn and Huson, Daniel H},
doi = {10.1038/ismej.2010.51},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitra et al. - 2010 - Comparison of multiple metagenomes using phylogenetic networks based on ecological indices.pdf:pdf},
issn = {1751-7370},
journal = {The ISME journal},
keywords = {Cluster Analysis,Ecosystem,Gene Expression Profiling,Metagenome,Metagenomics,Metagenomics: methods,Phylogeny,RNA, Ribosomal, 16S,RNA, Ribosomal, 16S: genetics},
month = oct,
number = {10},
pages = {1236--42},
pmid = {20428222},
publisher = {Nature Publishing Group},
title = {{Comparison of multiple metagenomes using phylogenetic networks based on ecological indices.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20428222},
volume = {4},
year = {2010}
}
@article{Yang2010a,
abstract = {With the rapid development of genome sequencing techniques, traditional research methods based on the isolation and cultivation of microorganisms are being gradually replaced by metagenomics, which is also known as environmental genomics. The first step, which is still a major bottleneck, of metagenomics is the taxonomic characterization of DNA fragments (reads) resulting from sequencing a sample of mixed species. This step is usually referred as "binning". Existing binning methods are based on supervised or semi-supervised approaches which rely heavily on reference genomes of known microorganisms and phylogenetic marker genes. Due to the limited availability of reference genomes and the bias and instability of marker genes, existing binning methods may not be applicable in many cases.},
author = {Yang, Bin and Peng, Yu and Leung, Henry Chi-Ming and Yiu, Siu-Ming and Chen, Jing-Chi and Chin, Francis Yuk-Lun},
doi = {10.1186/1471-2105-11-S2-S5},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2010 - Unsupervised binning of environmental genomic fragments based on an error robust selection of l-mers(3).pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Algorithms,Cluster Analysis,DNA,DNA: chemistry,Data Mining,Data Mining: methods,Databases, Genetic,Environmental Microbiology,Escherichia coli,Escherichia coli: genetics,Genome, Bacterial,Genome, Bacterial: genetics,Lactobacillus,Lactobacillus: genetics,Metagenomics,Metagenomics: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = jan,
number = {Suppl 2},
pages = {S5},
pmid = {20406503},
title = {{Unsupervised binning of environmental genomic fragments based on an error robust selection of l-mers.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3165929\&tool=pmcentrez\&rendertype=abstract},
volume = {11 Suppl 2},
year = {2010}
}
@article{Mitra2010a,
abstract = {Metagenomics is the study of environmental samples using sequencing. Rapid advances in sequencing technology are fueling a vast increase in the number and scope of metagenomics projects. Most metagenome sequencing projects so far have been based on Sanger or Roche-454 sequencing, as only these technologies provide long enough reads, while Illumina sequencing has not been considered suitable for metagenomic studies due to a short read length of only 35 bp. However, now that reads of length 75 bp can be sequenced in pairs, Illumina sequencing has become a viable option for metagenome studies.},
author = {Mitra, Suparna and Schubach, Max and Huson, Daniel H},
doi = {10.1186/1471-2105-11-S1-S12},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitra, Schubach, Huson - 2010 - Short clones or long clones A simulation study on the use of paired reads in metagenomics.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Base Sequence,Databases, Genetic,Genome,Metagenomics,Metagenomics: methods,Phylogeny,Sequence Alignment,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Software},
month = jan,
pages = {S12},
pmid = {20122183},
title = {{Short clones or long clones? A simulation study on the use of paired reads in metagenomics.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3009484\&tool=pmcentrez\&rendertype=abstract},
volume = {11 Suppl 1},
year = {2010}
}
@article{Mchardy2007a,
author = {Mchardy, Alice Carolyn},
doi = {10.1038/NMETH976},
file = {:home/binni/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mchardy - 2007 - Accurate phylogenetic classification of variable-length DNA fragments.pdf:pdf},
number = {1},
pages = {63--72},
title = {{Accurate phylogenetic classification of variable-length DNA fragments}},
volume = {4},
year = {2007}
}
@misc{Olman2009,
abstract = {Large sets of bioinformatical data provide a challenge in time consumption while solving the cluster identification problem, and that is why a parallel algorithm is so needed for identifying dense clusters in a noisy background. Our algorithm works on a graph representation of the data set to be analyzed. It identifies clusters through the identification of densely intraconnected subgraphs. We have employed a minimum spanning tree (MST) representation of the graph and solve the cluster identification problem using this representation. The computational bottleneck of our algorithm is the construction of an MST of a graph, for which a parallel algorithm is employed. Our high-level strategy for the parallel MST construction algorithm is to first partition the graph, then construct MSTs for the partitioned subgraphs and auxiliary bipartite graphs based on the subgraphs, and finally merge these MSTs to derive an MST of the original graph. The computational results indicate that when running on 150 CPUs, our algorithm can solve a cluster identification problem on a data set with 1,000,000 data points almost 100 times faster than on single CPU, indicating that this program is capable of handling very large data clustering problems in an efficient manner. We have implemented the clustering algorithm as the software CLUMP.},
author = {Olman, V and Mao, Fenglou Mao Fenglou and Wu, Hongwei Wu Hongwei and Xu, Ying Xu Ying},
booktitle = {IEEEACM Transactions on Computational Biology and Bioinformatics},
doi = {10.1109/TCBB.2007.70272},
file = {:home/binni/Downloads/04524229.pdf:pdf},
issn = {15455963},
keywords = {bioinformatics (genome protein) databases,clustering,clustering algorithm,genome application,parallel processing.,pattern recognition},
number = {2},
pages = {344--52},
publisher = {IEEE Computer Society},
title = {{Parallel Clustering Algorithm for Large Data Sets with Applications in Bioinformatics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19407357},
volume = {6},
year = {2009}
}
@article{Waltemath2013,
abstract = {Motivation: Only models that are accessible to researchers can be reused. As computational models evolve over time, a number of different but related versions of a model exist. Consequently, tools are required to manage not only well-curated models but also their associated versions. Results: In this work we discuss conceptual requirements for model version control. Focusing on XML formats such as SBML and CellML, we present methods for the identification and explanation of differences, and for the justification of changes between model versions. In consequence, researchers can reflect upon these changes, which in turn has considerable value for the development of new models. The implementation of model version control will therefore foster the exploration of published models and increase their reusability. Availability: We have implemented the proposed methods in a software library called BiVeS. It is freely available at http://sems.uni-rostock.de/bives/. BiVeS is also integrated in the online application BudHat which is available for testing at http://sems.uni-rostock.de/budhat/1. Contact: dagmar.waltemath@uni-rostock.de},
author = {Waltemath, D. and Henkel, R. and Halke, R. and Scharm, M. and Wolkenhauer, O.},
file = {:home/binni/Downloads/Bioinformatics-2013-Waltemath-bioinformatics\_btt018.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
keywords = {models,version control},
mendeley-tags = {models,version control},
month = jan,
pages = {btt018--},
title = {{Improving the reuse of computational models through version control}},
url = {http://bioinformatics.oxfordjournals.org/content/early/2013/01/18/bioinformatics.btt018.abstract},
year = {2013}
}
@inproceedings{Peng2010,
author = {Peng, Yu and Leung, H. and Yiu, S. and Chin, F.},
booktitle = {Research in Computational Molecular Biology},
file = {::},
keywords = {de bruijn graph,de novo assembly,high,mate-pair,string graph,throughput short reads},
pages = {426--440},
publisher = {Springer},
title = {{IDBA–A Practical Iterative de Bruijn Graph De Novo Assembler}},
url = {http://www.springerlink.com/index/622866948lh233g7.pdf},
year = {2010}
}
